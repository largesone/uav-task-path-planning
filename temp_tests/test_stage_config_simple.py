"""
ç®€åŒ–ç‰ˆé˜¶æ®µé…ç½®ç®¡ç†å™¨æµ‹è¯•
æµ‹è¯•è¯¾ç¨‹å­¦ä¹ é˜¶æ®µé…ç½®ç®¡ç†å’Œæœ€ä½³æ¨¡å‹ä¿å­˜åŠŸèƒ½
"""

import os
import sys
import unittest
import tempfile
import shutil
import json
import torch
import numpy as np
from pathlib import Path
from unittest.mock import Mock, patch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from stage_config_manager import StageConfig, StageConfigManager


class TestStageConfigSimple(unittest.TestCase):
    """æµ‹è¯•é˜¶æ®µé…ç½®æ•°æ®ç±»"""
    
    def test_stage_config_creation(self):
        """æµ‹è¯•é˜¶æ®µé…ç½®åˆ›å»º"""
        config = StageConfig(
            stage_id=1,
            n_uavs_range=(4, 6),
            n_targets_range=(3, 4),
            max_episodes=1500,
            success_threshold=0.75,
            fallback_threshold=0.55,
            learning_rate=0.0008,
            batch_size=128,
            exploration_noise=0.08,
            k_neighbors=6,
            description="æµ‹è¯•é˜¶æ®µ"
        )
        
        self.assertEqual(config.stage_id, 1)
        self.assertEqual(config.n_uavs_range, (4, 6))
        self.assertEqual(config.learning_rate, 0.0008)
        self.assertEqual(config.description, "æµ‹è¯•é˜¶æ®µ")
        print("âœ… é˜¶æ®µé…ç½®åˆ›å»ºæµ‹è¯•é€šè¿‡")
    
    def test_to_dict_conversion(self):
        """æµ‹è¯•è½¬æ¢ä¸ºå­—å…¸"""
        config = StageConfig(
            stage_id=0,
            n_uavs_range=(2, 3),
            n_targets_range=(1, 2),
            max_episodes=1000,
            success_threshold=0.8,
            fallback_threshold=0.6,
            learning_rate=0.001,
            batch_size=64,
            exploration_noise=0.1,
            k_neighbors=4
        )
        
        config_dict = config.to_dict()
        
        self.assertIsInstance(config_dict, dict)
        self.assertEqual(config_dict["stage_id"], 0)
        self.assertEqual(config_dict["learning_rate"], 0.001)
        self.assertIn("n_uavs_range", config_dict)
        print("âœ… å­—å…¸è½¬æ¢æµ‹è¯•é€šè¿‡")
    
    def test_from_dict_creation(self):
        """æµ‹è¯•ä»å­—å…¸åˆ›å»ºé…ç½®"""
        config_data = {
            "stage_id": 2,
            "n_uavs_range": [8, 12],
            "n_targets_range": [5, 8],
            "max_episodes": 2000,
            "success_threshold": 0.7,
            "fallback_threshold": 0.5,
            "learning_rate": 0.0005,
            "batch_size": 256,
            "exploration_noise": 0.06,
            "k_neighbors": 8,
            "description": "é«˜å¤æ‚åº¦é˜¶æ®µ"
        }
        
        config = StageConfig.from_dict(config_data)
        
        self.assertEqual(config.stage_id, 2)
        self.assertEqual(config.n_uavs_range, [8, 12])
        self.assertEqual(config.description, "é«˜å¤æ‚åº¦é˜¶æ®µ")
        print("âœ… ä»å­—å…¸åˆ›å»ºé…ç½®æµ‹è¯•é€šè¿‡")


class TestStageConfigManagerSimple(unittest.TestCase):
    """æµ‹è¯•é˜¶æ®µé…ç½®ç®¡ç†å™¨"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.test_dir = tempfile.mkdtemp()
        self.manager = StageConfigManager(self.test_dir)
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        shutil.rmtree(self.test_dir, ignore_errors=True)
    
    def test_initialization(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.assertTrue(Path(self.test_dir).exists())
        self.assertGreater(len(self.manager.stage_configs), 0)
        
        # éªŒè¯é»˜è®¤é…ç½®
        config_0 = self.manager.get_stage_config(0)
        self.assertIsNotNone(config_0)
        self.assertEqual(config_0.stage_id, 0)
        self.assertEqual(config_0.n_uavs_range, (2, 3))
        print("âœ… é˜¶æ®µé…ç½®ç®¡ç†å™¨åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")
    
    def test_get_stage_config(self):
        """æµ‹è¯•è·å–é˜¶æ®µé…ç½®"""
        # è·å–å­˜åœ¨çš„é…ç½®
        config = self.manager.get_stage_config(1)
        self.assertIsNotNone(config)
        self.assertEqual(config.stage_id, 1)
        
        # è·å–ä¸å­˜åœ¨çš„é…ç½®
        config = self.manager.get_stage_config(999)
        self.assertIsNone(config)
        print("âœ… è·å–é˜¶æ®µé…ç½®æµ‹è¯•é€šè¿‡")
    
    def test_update_stage_config(self):
        """æµ‹è¯•æ›´æ–°é˜¶æ®µé…ç½®"""
        # æ›´æ–°å­˜åœ¨çš„é…ç½®
        self.manager.update_stage_config(0, learning_rate=0.002, batch_size=128)
        
        config = self.manager.get_stage_config(0)
        self.assertEqual(config.learning_rate, 0.002)
        self.assertEqual(config.batch_size, 128)
        print("âœ… æ›´æ–°é˜¶æ®µé…ç½®æµ‹è¯•é€šè¿‡")
    
    def test_save_and_load_stage_config(self):
        """æµ‹è¯•ä¿å­˜å’ŒåŠ è½½é˜¶æ®µé…ç½®"""
        # ä¿®æ”¹é…ç½®
        original_lr = self.manager.get_stage_config(0).learning_rate
        self.manager.update_stage_config(0, learning_rate=0.005)
        
        # ä¿å­˜é…ç½®
        self.manager.save_stage_config(0)
        
        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        config_file = Path(self.test_dir) / "stage_0_config.json"
        self.assertTrue(config_file.exists())
        
        # é‡ç½®é…ç½®å¹¶é‡æ–°åŠ è½½
        self.manager.stage_configs[0].learning_rate = original_lr
        success = self.manager.load_stage_config(0)
        
        self.assertTrue(success)
        self.assertEqual(self.manager.get_stage_config(0).learning_rate, 0.005)
        print("âœ… ä¿å­˜å’ŒåŠ è½½é˜¶æ®µé…ç½®æµ‹è¯•é€šè¿‡")
    
    def test_save_and_load_best_model(self):
        """æµ‹è¯•ä¿å­˜å’ŒåŠ è½½æœ€ä½³æ¨¡å‹"""
        # åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å‹çŠ¶æ€
        model_state = {"layer1.weight": torch.randn(10, 5)}
        performance_metrics = {"normalized_completion_score": 0.85}
        training_config = {"learning_rate": 0.001}
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        self.manager.save_best_model(1, model_state, performance_metrics, training_config)
        
        # éªŒè¯å†…å­˜ä¸­çš„è®°å½•
        self.assertIn(1, self.manager.best_models)
        best_model_info = self.manager.best_models[1]
        self.assertEqual(best_model_info["stage_id"], 1)
        self.assertEqual(best_model_info["performance_metrics"]["normalized_completion_score"], 0.85)
        
        # éªŒè¯æ–‡ä»¶ä¿å­˜
        model_file = Path(self.test_dir) / "best_model_stage_1.pkl"
        self.assertTrue(model_file.exists())
        
        # æ¸…é™¤å†…å­˜è®°å½•å¹¶é‡æ–°åŠ è½½
        del self.manager.best_models[1]
        loaded_model_info = self.manager.load_best_model(1)
        
        self.assertIsNotNone(loaded_model_info)
        self.assertEqual(loaded_model_info["stage_id"], 1)
        self.assertEqual(loaded_model_info["performance_metrics"]["normalized_completion_score"], 0.85)
        print("âœ… ä¿å­˜å’ŒåŠ è½½æœ€ä½³æ¨¡å‹æµ‹è¯•é€šè¿‡")
    
    def test_record_stage_performance(self):
        """æµ‹è¯•è®°å½•é˜¶æ®µæ€§èƒ½"""
        performance_metrics = {
            "per_agent_reward": 12.5,
            "normalized_completion_score": 0.8,
            "efficiency_metric": 0.4
        }
        
        # è®°å½•æ€§èƒ½
        self.manager.record_stage_performance(0, performance_metrics, 100, 5000)
        
        # éªŒè¯è®°å½•
        self.assertIn(0, self.manager.stage_performance_history)
        history = self.manager.stage_performance_history[0]
        self.assertEqual(len(history), 1)
        
        record = history[0]
        self.assertEqual(record["episode"], 100)
        self.assertEqual(record["step"], 5000)
        self.assertEqual(record["per_agent_reward"], 12.5)
        print("âœ… è®°å½•é˜¶æ®µæ€§èƒ½æµ‹è¯•é€šè¿‡")
    
    def test_get_stage_performance_summary(self):
        """æµ‹è¯•è·å–é˜¶æ®µæ€§èƒ½æ‘˜è¦"""
        # è®°å½•å¤šä¸ªæ€§èƒ½æ•°æ®ç‚¹
        for i in range(10):
            performance = {
                "per_agent_reward": 10 + i,
                "normalized_completion_score": 0.7 + i * 0.02,
                "efficiency_metric": 0.3 + i * 0.01
            }
            self.manager.record_stage_performance(0, performance, i, i*100)
        
        # è·å–æ‘˜è¦
        summary = self.manager.get_stage_performance_summary(0)
        
        # éªŒè¯æ‘˜è¦å†…å®¹
        self.assertEqual(summary["total_records"], 10)
        self.assertEqual(summary["first_episode"], 0)
        self.assertEqual(summary["last_episode"], 9)
        
        # éªŒè¯ç»Ÿè®¡æŒ‡æ ‡
        self.assertIn("per_agent_reward_mean", summary)
        self.assertIn("normalized_completion_score_max", summary)
        self.assertAlmostEqual(summary["per_agent_reward_mean"], 14.5)  # (10+19)/2
        print("âœ… è·å–é˜¶æ®µæ€§èƒ½æ‘˜è¦æµ‹è¯•é€šè¿‡")
    
    def test_should_advance_stage(self):
        """æµ‹è¯•é˜¶æ®µæ¨è¿›åˆ¤æ–­"""
        # è®°å½•é«˜æ€§èƒ½æ•°æ®ï¼ˆåº”è¯¥æ¨è¿›ï¼‰
        for i in range(5):
            performance = {"normalized_completion_score": 0.85}  # é«˜äºé˜ˆå€¼0.8
            self.manager.record_stage_performance(0, performance, i, i*100)
        
        current_performance = {"normalized_completion_score": 0.85}
        should_advance = self.manager.should_advance_stage(0, current_performance, 3)
        self.assertTrue(should_advance)
        
        # è®°å½•ä½æ€§èƒ½æ•°æ®ï¼ˆä¸åº”è¯¥æ¨è¿›ï¼‰
        low_performance = {"normalized_completion_score": 0.7}  # ä½äºé˜ˆå€¼
        should_advance = self.manager.should_advance_stage(0, low_performance, 3)
        self.assertFalse(should_advance)
        print("âœ… é˜¶æ®µæ¨è¿›åˆ¤æ–­æµ‹è¯•é€šè¿‡")
    
    def test_should_fallback_stage(self):
        """æµ‹è¯•é˜¶æ®µå›é€€åˆ¤æ–­"""
        # ç¬¬0é˜¶æ®µä¸åº”è¯¥å›é€€
        low_performance = {"normalized_completion_score": 0.5}
        should_fallback = self.manager.should_fallback_stage(0, low_performance, 3)
        self.assertFalse(should_fallback)
        
        # è®°å½•ä½æ€§èƒ½æ•°æ®åˆ°é˜¶æ®µ1ï¼ˆåº”è¯¥å›é€€ï¼‰
        for i in range(5):
            performance = {"normalized_completion_score": 0.5}  # ä½äºå›é€€é˜ˆå€¼0.55
            self.manager.record_stage_performance(1, performance, i, i*100)
        
        current_performance = {"normalized_completion_score": 0.5}
        should_fallback = self.manager.should_fallback_stage(1, current_performance, 3)
        self.assertTrue(should_fallback)
        print("âœ… é˜¶æ®µå›é€€åˆ¤æ–­æµ‹è¯•é€šè¿‡")
    
    def test_get_adaptive_learning_rate(self):
        """æµ‹è¯•è‡ªé€‚åº”å­¦ä¹ ç‡"""
        # æµ‹è¯•æ€§èƒ½æå‡è¶‹åŠ¿
        improving_trend = [0.6, 0.65, 0.7, 0.75, 0.8]
        adaptive_lr = self.manager.get_adaptive_learning_rate(0, improving_trend)
        base_lr = self.manager.get_stage_config(0).learning_rate
        self.assertGreater(adaptive_lr, base_lr)  # åº”è¯¥å¢åŠ å­¦ä¹ ç‡
        
        # æµ‹è¯•æ€§èƒ½ä¸‹é™è¶‹åŠ¿
        declining_trend = [0.8, 0.75, 0.7, 0.65, 0.6]
        adaptive_lr = self.manager.get_adaptive_learning_rate(0, declining_trend)
        self.assertLess(adaptive_lr, base_lr)  # åº”è¯¥é™ä½å­¦ä¹ ç‡
        
        # æµ‹è¯•ç¨³å®šè¶‹åŠ¿
        stable_trend = [0.7, 0.7, 0.7, 0.7, 0.7]
        adaptive_lr = self.manager.get_adaptive_learning_rate(0, stable_trend)
        self.assertAlmostEqual(adaptive_lr, base_lr)  # åº”è¯¥ä¿æŒå­¦ä¹ ç‡
        print("âœ… è‡ªé€‚åº”å­¦ä¹ ç‡æµ‹è¯•é€šè¿‡")
    
    def test_get_adaptive_k_neighbors(self):
        """æµ‹è¯•è‡ªé€‚åº”kè¿‘é‚»"""
        # å°è§„æ¨¡åœºæ™¯
        k_small = self.manager.get_adaptive_k_neighbors(0, 3, 2)  # scale_factor = 6
        self.assertLessEqual(k_small, 2)  # kä¸åº”è¶…è¿‡ç›®æ ‡æ•°é‡
        
        # ä¸­ç­‰è§„æ¨¡åœºæ™¯
        k_medium = self.manager.get_adaptive_k_neighbors(1, 5, 4)  # scale_factor = 20
        self.assertGreaterEqual(k_medium, 4)
        self.assertLessEqual(k_medium, 4)
        
        # å¤§è§„æ¨¡åœºæ™¯
        k_large = self.manager.get_adaptive_k_neighbors(2, 10, 8)  # scale_factor = 80
        self.assertGreaterEqual(k_large, 6)
        self.assertLessEqual(k_large, 8)
        print("âœ… è‡ªé€‚åº”kè¿‘é‚»æµ‹è¯•é€šè¿‡")
    
    def test_export_and_import_configs(self):
        """æµ‹è¯•é…ç½®å¯¼å‡ºå’Œå¯¼å…¥"""
        # ä¿®æ”¹ä¸€äº›é…ç½®
        self.manager.update_stage_config(0, learning_rate=0.002)
        self.manager.update_stage_config(1, batch_size=256)
        
        # å¯¼å‡ºé…ç½®
        export_file = self.manager.export_all_configs()
        self.assertTrue(os.path.exists(export_file))
        
        # éªŒè¯å¯¼å‡ºæ–‡ä»¶å†…å®¹
        with open(export_file, 'r', encoding='utf-8') as f:
            exported_data = json.load(f)
        
        self.assertIn("configs", exported_data)
        self.assertIn("export_timestamp", exported_data)
        self.assertEqual(exported_data["configs"]["0"]["learning_rate"], 0.002)
        
        # é‡ç½®é…ç½®å¹¶å¯¼å…¥
        self.manager.stage_configs[0].learning_rate = 0.001
        success = self.manager.import_configs(export_file)
        
        self.assertTrue(success)
        self.assertEqual(self.manager.get_stage_config(0).learning_rate, 0.002)
        print("âœ… é…ç½®å¯¼å‡ºå’Œå¯¼å…¥æµ‹è¯•é€šè¿‡")
    
    def test_get_stage_transition_recommendation(self):
        """æµ‹è¯•é˜¶æ®µåˆ‡æ¢å»ºè®®"""
        # æµ‹è¯•æ€§èƒ½è¾¾æ ‡çš„æƒ…å†µ
        high_performance = [
            {"normalized_completion_score": 0.85},
            {"normalized_completion_score": 0.87},
            {"normalized_completion_score": 0.89}
        ]
        
        # å…ˆè®°å½•å†å²æ€§èƒ½
        for i, perf in enumerate(high_performance):
            self.manager.record_stage_performance(0, perf, i, i*100)
        
        recommendation = self.manager.get_stage_transition_recommendation(0, high_performance)
        self.assertEqual(recommendation["action"], "advance")
        self.assertEqual(recommendation["target_stage"], 1)
        
        # æµ‹è¯•æ€§èƒ½ä¸è¶³çš„æƒ…å†µ
        low_performance = [{"normalized_completion_score": 0.5}] * 5
        for i, perf in enumerate(low_performance):
            self.manager.record_stage_performance(1, perf, i, i*100)
        
        recommendation = self.manager.get_stage_transition_recommendation(1, low_performance)
        self.assertEqual(recommendation["action"], "fallback")
        self.assertEqual(recommendation["target_stage"], 0)
        print("âœ… é˜¶æ®µåˆ‡æ¢å»ºè®®æµ‹è¯•é€šè¿‡")


class TestStageConfigIntegrationSimple(unittest.TestCase):
    """ç®€åŒ–ç‰ˆé˜¶æ®µé…ç½®é›†æˆæµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.test_dir = tempfile.mkdtemp()
        self.manager = StageConfigManager(self.test_dir)
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        shutil.rmtree(self.test_dir, ignore_errors=True)
    
    def test_complete_stage_management_workflow(self):
        """æµ‹è¯•å®Œæ•´çš„é˜¶æ®µç®¡ç†å·¥ä½œæµ"""
        print("ğŸ”„ å¼€å§‹å®Œæ•´é˜¶æ®µç®¡ç†å·¥ä½œæµæµ‹è¯•...")
        
        # 1. æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹ä¸­çš„é˜¶æ®µç®¡ç†
        current_stage = 0
        
        # 2. è®°å½•è®­ç»ƒæ€§èƒ½
        for episode in range(50):
            # æ¨¡æ‹Ÿæ€§èƒ½é€æ¸æå‡
            performance = {
                "per_agent_reward": 10 + episode * 0.1,
                "normalized_completion_score": 0.6 + episode * 0.005,
                "efficiency_metric": 0.3 + episode * 0.002
            }
            
            self.manager.record_stage_performance(current_stage, performance, episode, episode*100)
            
            # æ¯10ä¸ªepisodeæ£€æŸ¥ä¸€æ¬¡æ˜¯å¦éœ€è¦åˆ‡æ¢é˜¶æ®µ
            if episode % 10 == 9:
                recent_performance = [performance] * 3  # ç®€åŒ–ï¼šä½¿ç”¨å½“å‰æ€§èƒ½ä½œä¸ºæœ€è¿‘æ€§èƒ½
                recommendation = self.manager.get_stage_transition_recommendation(current_stage, recent_performance)
                
                if recommendation["action"] == "advance" and current_stage < 3:
                    # ä¿å­˜å½“å‰é˜¶æ®µçš„æœ€ä½³æ¨¡å‹
                    model_state = {"layer1.weight": torch.randn(10, 5)}
                    self.manager.save_best_model(current_stage, model_state, performance, {"lr": 0.001})
                    
                    current_stage += 1
                    print(f"   é˜¶æ®µåˆ‡æ¢: {current_stage-1} -> {current_stage}")
        
        # 3. éªŒè¯ç»“æœ
        # æ£€æŸ¥æ€§èƒ½å†å²è®°å½•
        self.assertGreater(len(self.manager.stage_performance_history), 0)
        
        # æ£€æŸ¥æœ€ä½³æ¨¡å‹ä¿å­˜
        self.assertGreater(len(self.manager.best_models), 0)
        
        # æ£€æŸ¥é…ç½®ç®¡ç†
        for stage_id in range(current_stage + 1):
            config = self.manager.get_stage_config(stage_id)
            self.assertIsNotNone(config)
            
            summary = self.manager.get_stage_performance_summary(stage_id)
            if summary:  # å¦‚æœæœ‰æ€§èƒ½è®°å½•
                self.assertGreater(summary["total_records"], 0)
        
        # 4. æµ‹è¯•è‡ªé€‚åº”å‚æ•°è°ƒæ•´
        performance_trend = [0.6, 0.65, 0.7, 0.75, 0.8]
        adaptive_lr = self.manager.get_adaptive_learning_rate(0, performance_trend)
        self.assertIsInstance(adaptive_lr, float)
        
        adaptive_k = self.manager.get_adaptive_k_neighbors(0, 5, 3)
        self.assertIsInstance(adaptive_k, int)
        
        # 5. æµ‹è¯•é…ç½®æŒä¹…åŒ–
        self.manager.save_all_data()
        
        print("âœ… å®Œæ•´é˜¶æ®µç®¡ç†å·¥ä½œæµæµ‹è¯•é€šè¿‡")


def run_simple_stage_config_tests():
    """è¿è¡Œç®€åŒ–ç‰ˆé˜¶æ®µé…ç½®ç®¡ç†å™¨æµ‹è¯•"""
    print("âš™ï¸ å¼€å§‹ç®€åŒ–ç‰ˆé˜¶æ®µé…ç½®ç®¡ç†å™¨æµ‹è¯•...")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestSuite()
    
    # æ·»åŠ æµ‹è¯•ç±»
    test_classes = [
        TestStageConfigSimple,
        TestStageConfigManagerSimple,
        TestStageConfigIntegrationSimple
    ]
    
    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        test_suite.addTests(tests)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=1)
    result = runner.run(test_suite)
    
    # è¾“å‡ºç»“æœæ‘˜è¦
    print(f"\nğŸ“Š ç®€åŒ–ç‰ˆé˜¶æ®µé…ç½®æµ‹è¯•ç»“æœæ‘˜è¦:")
    print(f"   æ€»æµ‹è¯•æ•°: {result.testsRun}")
    print(f"   æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"   å¤±è´¥: {len(result.failures)}")
    print(f"   é”™è¯¯: {len(result.errors)}")
    
    if result.failures:
        print(f"\nâŒ å¤±è´¥çš„æµ‹è¯•:")
        for failure in result.failures:
            print(f"   - {failure[0]}: {failure[1].split('AssertionError:')[-1].strip()}")
    
    if result.errors:
        print(f"\nğŸ’¥ é”™è¯¯çš„æµ‹è¯•:")
        for error in result.errors:
            print(f"   - {error[0]}: {error[1].split('Exception:')[-1].strip()}")
    
    return result.wasSuccessful()


if __name__ == "__main__":
    success = run_simple_stage_config_tests()
    sys.exit(0 if success else 1)
