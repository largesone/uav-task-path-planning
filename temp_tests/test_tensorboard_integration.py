"""
TensorBoardé›†æˆæµ‹è¯•
æµ‹è¯•è‡ªå®šä¹‰TensorBoardåŠŸèƒ½å’Œé«˜çº§å¯è§†åŒ–
"""

import os
import sys
import unittest
import tempfile
import shutil
import torch
import numpy as np
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from tensorboard_integration import CurriculumTensorBoardWriter, TensorBoardCustomPlugin


class TestCurriculumTensorBoardWriter(unittest.TestCase):
    """æµ‹è¯•è¯¾ç¨‹å­¦ä¹ TensorBoardå†™å…¥å™¨"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.test_dir = tempfile.mkdtemp()
        self.writer = CurriculumTensorBoardWriter(self.test_dir, "test_experiment")
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        self.writer.close()
        shutil.rmtree(self.test_dir, ignore_errors=True)
    
    def test_initialization(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.assertTrue(self.writer.tb_dir.exists())
        self.assertEqual(self.writer.experiment_name, "test_experiment")
        self.assertIsNotNone(self.writer.writer)
        self.assertIn("Scale_Invariant_Metrics", self.writer.scalar_groups)
    
    @patch('torch.utils.tensorboard.SummaryWriter.add_hparams')
    def test_log_hparams(self, mock_add_hparams):
        """æµ‹è¯•è¶…å‚æ•°è®°å½•"""
        hparams = {
            "learning_rate": 0.001,
            "batch_size": 128,
            "k_neighbors": 8
        }
        metrics = {
            "final_performance": 0.85,
            "total_episodes": 1000
        }
        
        self.writer.log_hparams(hparams, metrics)
        
        # éªŒè¯è¶…å‚æ•°è¢«è®°å½•
        mock_add_hparams.assert_called_once()
        self.assertEqual(len(self.writer.hparams), 3)
    
    @patch('torch.utils.tensorboard.SummaryWriter.add_scalar')
    @patch('torch.utils.tensorboard.SummaryWriter.add_text')
    def test_log_curriculum_stage_transition(self, mock_add_text, mock_add_scalar):
        """æµ‹è¯•è¯¾ç¨‹å­¦ä¹ é˜¶æ®µåˆ‡æ¢è®°å½•"""
        performance_data = {
            "normalized_completion_score": 0.85,
            "per_agent_reward": 12.5
        }
        
        self.writer.log_curriculum_stage_transition(0, 1, 1000, performance_data)
        
        # éªŒè¯æ ‡é‡å’Œæ–‡æœ¬è¢«è®°å½•
        mock_add_scalar.assert_called()
        mock_add_text.assert_called()
    
    @patch('torch.utils.tensorboard.SummaryWriter.add_scalar')
    def test_log_scale_invariant_metrics_detailed(self, mock_add_scalar):
        """æµ‹è¯•è¯¦ç»†å°ºåº¦ä¸å˜æŒ‡æ ‡è®°å½•"""
        metrics = {
            "per_agent_reward": 12.5,
            "normalized_completion_score": 0.85,
            "efficiency_metric": 0.42
        }
        scenario_info = {
            "n_uavs": 5,
            "n_targets": 3
        }
        
        self.writer.log_scale_invariant_metrics_detailed(metrics, 1000, 1, scenario_info)
        
        # éªŒè¯æ‰€æœ‰æŒ‡æ ‡è¢«è®°å½•
        expected_calls = len(metrics) + len(scenario_info) + 2  # +2 for scale_factor and performance_density
        self.assertGreaterEqual(mock_add_scalar.call_count, expected_calls)
    
    @patch('torch.utils.tensorboard.SummaryWriter.add_figure')
    @patch('torch.utils.tensorboard.SummaryWriter.add_histogram')
    @patch('torch.utils.tensorboard.SummaryWriter.add_scalar')
    def test_log_attention_weights(self, mock_add_scalar, mock_add_histogram, mock_add_figure):
        """æµ‹è¯•æ³¨æ„åŠ›æƒé‡è®°å½•"""
        # åˆ›å»ºæ¨¡æ‹Ÿæ³¨æ„åŠ›æƒé‡ [batch, heads, seq_len, seq_len]
        attention_weights = torch.rand(2, 4, 10, 10)
        
        self.writer.log_attention_weights(attention_weights, 1000, "test_layer")
        
        # éªŒè¯å›¾è¡¨ã€ç›´æ–¹å›¾å’Œæ ‡é‡è¢«è®°å½•
        mock_add_figure.assert_called_once()
        mock_add_histogram.assert_called_once()
        mock_add_scalar.assert_called_once()
    
    @patch('torch.utils.tensorboard.SummaryWriter.add_scalar')
    @patch('torch.utils.tensorboard.SummaryWriter.add_histogram')
    def test_log_model_gradients(self, mock_add_histogram, mock_add_scalar):
        """æµ‹è¯•æ¨¡å‹æ¢¯åº¦è®°å½•"""
        # åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å‹
        model = torch.nn.Linear(10, 5)
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ¢¯åº¦
        for param in model.parameters():
            param.grad = torch.randn_like(param)
        
        self.writer.log_model_gradients(model, 1000)
        
        # éªŒè¯æ¢¯åº¦ä¿¡æ¯è¢«è®°å½•
        self.assertGreater(mock_add_scalar.call_count, 0)
        self.assertGreater(mock_add_histogram.call_count, 0)
    
    @patch('torch.utils.tensorboard.SummaryWriter.add_figure')
    def test_log_learning_curves(self, mock_add_figure):
        """æµ‹è¯•å­¦ä¹ æ›²çº¿è®°å½•"""
        train_metrics = {
            "loss": [1.0, 0.8, 0.6, 0.4],
            "accuracy": [0.6, 0.7, 0.8, 0.9]
        }
        val_metrics = {
            "loss": [1.2, 0.9, 0.7, 0.5],
            "accuracy": [0.5, 0.65, 0.75, 0.85]
        }
        steps = [100, 200, 300, 400]
        
        self.writer.log_learning_curves(train_metrics, val_metrics, steps)
        
        # éªŒè¯å­¦ä¹ æ›²çº¿å›¾è¢«åˆ›å»º
        self.assertEqual(mock_add_figure.call_count, 2)  # losså’Œaccuracyå„ä¸€ä¸ª
    
    @patch('torch.utils.tensorboard.SummaryWriter.add_text')
    def test_log_curriculum_progress_summary(self, mock_add_text):
        """æµ‹è¯•è¯¾ç¨‹å­¦ä¹ è¿›åº¦æ‘˜è¦è®°å½•"""
        stage_summaries = {
            0: {"completed": True, "best_performance": 0.85, "total_steps": 1000, "n_uavs": 3, "n_targets": 2},
            1: {"completed": False, "best_performance": 0.75, "total_steps": 500, "n_uavs": 5, "n_targets": 3}
        }
        
        self.writer.log_curriculum_progress_summary(stage_summaries, 1500)
        
        # éªŒè¯æ‘˜è¦æ–‡æœ¬è¢«è®°å½•
        mock_add_text.assert_called()
    
    def test_calculate_attention_entropy(self):
        """æµ‹è¯•æ³¨æ„åŠ›ç†µè®¡ç®—"""
        # åˆ›å»ºå‡åŒ€åˆ†å¸ƒçš„æ³¨æ„åŠ›æƒé‡ï¼ˆé«˜ç†µï¼‰
        uniform_attention = torch.ones(5, 5) / 25
        high_entropy = self.writer._calculate_attention_entropy(uniform_attention)
        
        # åˆ›å»ºé›†ä¸­åˆ†å¸ƒçš„æ³¨æ„åŠ›æƒé‡ï¼ˆä½ç†µï¼‰
        concentrated_attention = torch.zeros(5, 5)
        concentrated_attention[0, 0] = 1.0
        low_entropy = self.writer._calculate_attention_entropy(concentrated_attention)
        
        # éªŒè¯ç†µçš„ç›¸å¯¹å¤§å°
        self.assertGreater(high_entropy, low_entropy)


class TestTensorBoardCustomPlugin(unittest.TestCase):
    """æµ‹è¯•TensorBoardè‡ªå®šä¹‰æ’ä»¶"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.test_dir = tempfile.mkdtemp()
        self.plugin = TensorBoardCustomPlugin(self.test_dir)
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        shutil.rmtree(self.test_dir, ignore_errors=True)
    
    def test_initialization(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.assertTrue(self.plugin.plugin_dir.exists())
    
    def test_create_curriculum_dashboard_config(self):
        """æµ‹è¯•åˆ›å»ºè¯¾ç¨‹å­¦ä¹ ä»ªè¡¨æ¿é…ç½®"""
        config_path = self.plugin.create_curriculum_dashboard_config()
        
        # éªŒè¯é…ç½®æ–‡ä»¶å­˜åœ¨
        self.assertTrue(os.path.exists(config_path))
        
        # éªŒè¯é…ç½®å†…å®¹
        import json
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        self.assertIn("name", config)
        self.assertIn("layout", config)
        self.assertIn("sections", config["layout"])
    
    def test_generate_custom_html_dashboard(self):
        """æµ‹è¯•ç”Ÿæˆè‡ªå®šä¹‰HTMLä»ªè¡¨æ¿"""
        html_path = self.plugin.generate_custom_html_dashboard("test_experiment")
        
        # éªŒè¯HTMLæ–‡ä»¶å­˜åœ¨
        self.assertTrue(os.path.exists(html_path))
        
        # éªŒè¯HTMLå†…å®¹
        with open(html_path, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        self.assertIn("test_experiment", html_content)
        self.assertIn("è¯¾ç¨‹å­¦ä¹ è®­ç»ƒç›‘æ§ä»ªè¡¨æ¿", html_content)
        self.assertIn("plotly", html_content.lower())


class TestTensorBoardIntegrationScenarios(unittest.TestCase):
    """TensorBoardé›†æˆåœºæ™¯æµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.test_dir = tempfile.mkdtemp()
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        shutil.rmtree(self.test_dir, ignore_errors=True)
    
    def test_complete_tensorboard_workflow(self):
        """æµ‹è¯•å®Œæ•´çš„TensorBoardå·¥ä½œæµ"""
        # 1. åˆå§‹åŒ–å†™å…¥å™¨
        writer = CurriculumTensorBoardWriter(self.test_dir, "workflow_test")
        
        # 2. è®°å½•è¶…å‚æ•°
        hparams = {"learning_rate": 0.001, "batch_size": 128}
        metrics = {"final_score": 0.85}
        
        with patch.object(writer.writer, 'add_hparams'):
            writer.log_hparams(hparams, metrics)
        
        # 3. æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹è®°å½•
        with patch.object(writer.writer, 'add_scalar') as mock_scalar:
            for step in range(0, 1000, 100):
                stage = step // 300
                
                # è®°å½•æŒ‡æ ‡
                test_metrics = {
                    "per_agent_reward": 10 + np.random.normal(0, 1),
                    "normalized_completion_score": 0.7 + np.random.uniform(-0.1, 0.2),
                    "efficiency_metric": 0.3 + np.random.uniform(-0.05, 0.1)
                }
                scenario_info = {"n_uavs": 5, "n_targets": 3}
                
                writer.log_scale_invariant_metrics_detailed(test_metrics, step, stage, scenario_info)
                
                # æ¨¡æ‹Ÿé˜¶æ®µåˆ‡æ¢
                if step in [300, 600]:
                    with patch.object(writer.writer, 'add_text'):
                        writer.log_curriculum_stage_transition(stage-1, stage, step, test_metrics)
        
        # 4. è®°å½•æ¨¡å‹ç›¸å…³ä¿¡æ¯
        model = torch.nn.Linear(10, 5)
        for param in model.parameters():
            param.grad = torch.randn_like(param)
        
        with patch.object(writer.writer, 'add_histogram'), \
             patch.object(writer.writer, 'add_scalar'):
            writer.log_model_gradients(model, 1000)
        
        # 5. è®°å½•æ³¨æ„åŠ›æƒé‡
        attention_weights = torch.rand(2, 4, 8, 8)
        with patch.object(writer.writer, 'add_figure'), \
             patch.object(writer.writer, 'add_histogram'), \
             patch.object(writer.writer, 'add_scalar'):
            writer.log_attention_weights(attention_weights, 1000)
        
        # 6. æ¸…ç†
        writer.close()
        
        print("âœ… å®Œæ•´TensorBoardå·¥ä½œæµæµ‹è¯•é€šè¿‡")
    
    def test_plugin_integration(self):
        """æµ‹è¯•æ’ä»¶é›†æˆ"""
        plugin = TensorBoardCustomPlugin(self.test_dir)
        
        # åˆ›å»ºé…ç½®å’Œä»ªè¡¨æ¿
        config_path = plugin.create_curriculum_dashboard_config()
        html_path = plugin.generate_custom_html_dashboard("integration_test")
        
        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        self.assertTrue(os.path.exists(config_path))
        self.assertTrue(os.path.exists(html_path))
        
        print("âœ… TensorBoardæ’ä»¶é›†æˆæµ‹è¯•é€šè¿‡")


def run_tensorboard_integration_tests():
    """è¿è¡Œæ‰€æœ‰TensorBoardé›†æˆæµ‹è¯•"""
    print("ğŸ“Š å¼€å§‹TensorBoardé›†æˆæµ‹è¯•...")
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestSuite()
    
    # æ·»åŠ æµ‹è¯•ç±»
    test_classes = [
        TestCurriculumTensorBoardWriter,
        TestTensorBoardCustomPlugin,
        TestTensorBoardIntegrationScenarios
    ]
    
    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        test_suite.addTests(tests)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # è¾“å‡ºç»“æœæ‘˜è¦
    print(f"\nğŸ“Š TensorBoardé›†æˆæµ‹è¯•ç»“æœæ‘˜è¦:")
    print(f"   æ€»æµ‹è¯•æ•°: {result.testsRun}")
    print(f"   æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"   å¤±è´¥: {len(result.failures)}")
    print(f"   é”™è¯¯: {len(result.errors)}")
    
    return result.wasSuccessful()


if __name__ == "__main__":
    success = run_tensorboard_integration_tests()
    sys.exit(0 if success else 1)
