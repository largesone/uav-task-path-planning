"""
ä»»åŠ¡14åŠŸèƒ½æ¼”ç¤º
å±•ç¤ºè®­ç»ƒæ•°æ®ä¿å­˜ä¸TensorBoardé›†æˆçš„æ ¸å¿ƒåŠŸèƒ½
"""

import os
import sys
import tempfile
import shutil
import torch
import numpy as np
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from training_logger import CurriculumTensorBoardLogger, ModelCheckpointManager, create_training_config_with_logging
from stage_config_manager import StageConfigManager


def demonstrate_task14_functionality():
    """æ¼”ç¤ºä»»åŠ¡14çš„æ ¸å¿ƒåŠŸèƒ½"""
    print("ğŸ¯ ä»»åŠ¡14åŠŸèƒ½æ¼”ç¤ºï¼šè®­ç»ƒæ•°æ®ä¿å­˜ä¸TensorBoardé›†æˆ")
    print("=" * 60)
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    demo_dir = tempfile.mkdtemp()
    print(f"ğŸ“ æ¼”ç¤ºç›®å½•: {demo_dir}")
    
    try:
        # 1. æ¼”ç¤ºTensorBoardæ—¥å¿—è®°å½•å™¨
        print("\n1ï¸âƒ£ TensorBoardæ—¥å¿—è®°å½•å™¨æ¼”ç¤º")
        print("-" * 40)
        
        logger = CurriculumTensorBoardLogger(demo_dir, "demo_experiment")
        
        # æ¨¡æ‹Ÿè¯¾ç¨‹å­¦ä¹ è®­ç»ƒè¿‡ç¨‹
        stages = [
            {"stage": 0, "n_uavs": 3, "n_targets": 2, "description": "åŸºç¡€é˜¶æ®µ"},
            {"stage": 1, "n_uavs": 5, "n_targets": 3, "description": "ä¸­ç­‰å¤æ‚åº¦"},
            {"stage": 2, "n_uavs": 8, "n_targets": 5, "description": "é«˜å¤æ‚åº¦"}
        ]
        
        for i, stage_info in enumerate(stages):
            print(f"   ğŸ”„ æ¨¡æ‹Ÿé˜¶æ®µ {stage_info['stage']} ({stage_info['description']})")
            
            # æ¨¡æ‹Ÿè¯¥é˜¶æ®µçš„è®­ç»ƒæ­¥éª¤
            for step in range(i*1000, (i+1)*1000, 200):
                # ç”Ÿæˆæ¨¡æ‹Ÿçš„å°ºåº¦ä¸å˜æŒ‡æ ‡
                metrics = {
                    "per_agent_reward": 10 + np.random.normal(0, 1),
                    "normalized_completion_score": 0.6 + i*0.1 + np.random.uniform(-0.05, 0.1),
                    "efficiency_metric": 0.3 + i*0.05 + np.random.uniform(-0.02, 0.05)
                }
                
                # è®°å½•æŒ‡æ ‡
                logger.log_scale_invariant_metrics(
                    metrics, step, stage_info['stage'], 
                    stage_info['n_uavs'], stage_info['n_targets']
                )
                
                print(f"      ğŸ“Š æ­¥æ•° {step}: å®Œæˆåˆ†æ•° {metrics['normalized_completion_score']:.3f}")
            
            # è®°å½•é˜¶æ®µåˆ‡æ¢
            if i < len(stages) - 1:
                next_stage = stages[i+1]['stage']
                logger.log_stage_transition(
                    stage_info['stage'], next_stage, (i+1)*1000, 
                    "performance_threshold"
                )
                print(f"      â¡ï¸  é˜¶æ®µåˆ‡æ¢: {stage_info['stage']} -> {next_stage}")
        
        # æ¨¡æ‹Ÿä¸€ä¸ªå›é€€äº‹ä»¶
        logger.log_rollback_event(2, 2500, 0.12, 0.1)
        print(f"      â¬…ï¸  å›é€€äº‹ä»¶: é˜¶æ®µ2æ€§èƒ½ä¸‹é™0.12 > é˜ˆå€¼0.1")
        
        print("   âœ… TensorBoardæ—¥å¿—è®°å½•å®Œæˆ")
        
        # 2. æ¼”ç¤ºæ¨¡å‹æ£€æŸ¥ç‚¹ç®¡ç†å™¨
        print("\n2ï¸âƒ£ æ¨¡å‹æ£€æŸ¥ç‚¹ç®¡ç†å™¨æ¼”ç¤º")
        print("-" * 40)
        
        checkpoint_manager = ModelCheckpointManager(os.path.join(demo_dir, "checkpoints"))
        
        # æ¨¡æ‹Ÿä¿å­˜å¤šä¸ªæ£€æŸ¥ç‚¹
        for i in range(5):
            # åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å‹çŠ¶æ€
            model_state = {
                "transformer.weight": torch.randn(64, 32),
                "output.bias": torch.randn(10)
            }
            optimizer_state = {"lr": 0.001 - i*0.0001}
            metrics = {"normalized_completion_score": 0.7 + i*0.05}
            
            is_best = (i == 3)  # ç¬¬4ä¸ªæ˜¯æœ€ä½³çš„
            checkpoint_path = checkpoint_manager.save_checkpoint(
                model_state, optimizer_state, metrics, 
                i*500, i//2, is_best
            )
            
            status = "ğŸ† æœ€ä½³" if is_best else "ğŸ“ å¸¸è§„"
            print(f"   {status} æ£€æŸ¥ç‚¹ {i+1}: æ€§èƒ½ {metrics['normalized_completion_score']:.3f}")
        
        # è·å–æœ€ä½³æ£€æŸ¥ç‚¹
        best_checkpoint = checkpoint_manager.get_best_checkpoint()
        if best_checkpoint:
            loaded_data = checkpoint_manager.load_checkpoint(best_checkpoint)
            print(f"   ğŸ”„ åŠ è½½æœ€ä½³æ£€æŸ¥ç‚¹: æ€§èƒ½ {loaded_data['metrics']['normalized_completion_score']:.3f}")
        
        print("   âœ… æ¨¡å‹æ£€æŸ¥ç‚¹ç®¡ç†å®Œæˆ")
        
        # 3. æ¼”ç¤ºé˜¶æ®µé…ç½®ç®¡ç†å™¨
        print("\n3ï¸âƒ£ é˜¶æ®µé…ç½®ç®¡ç†å™¨æ¼”ç¤º")
        print("-" * 40)
        
        config_manager = StageConfigManager(os.path.join(demo_dir, "configs"))
        
        # æ˜¾ç¤ºé»˜è®¤é…ç½®
        for stage_id in range(4):
            config = config_manager.get_stage_config(stage_id)
            print(f"   âš™ï¸  é˜¶æ®µ {stage_id}: {config.n_uavs_range[0]}-{config.n_uavs_range[1]} UAVs, "
                  f"{config.n_targets_range[0]}-{config.n_targets_range[1]} ç›®æ ‡, "
                  f"å­¦ä¹ ç‡ {config.learning_rate}")
        
        # æ¨¡æ‹Ÿæ€§èƒ½è®°å½•å’Œé…ç½®è°ƒæ•´
        for stage_id in range(3):
            # è®°å½•æ€§èƒ½æ•°æ®
            for episode in range(5):
                performance = {
                    "per_agent_reward": 10 + stage_id*2 + np.random.normal(0, 0.5),
                    "normalized_completion_score": 0.6 + stage_id*0.1 + np.random.uniform(-0.05, 0.1),
                    "efficiency_metric": 0.3 + stage_id*0.05 + np.random.uniform(-0.02, 0.05)
                }
                config_manager.record_stage_performance(stage_id, performance, episode, episode*100)
            
            # è·å–æ€§èƒ½æ‘˜è¦
            summary = config_manager.get_stage_performance_summary(stage_id)
            if summary:
                print(f"   ğŸ“ˆ é˜¶æ®µ {stage_id} å¹³å‡æ€§èƒ½: {summary.get('normalized_completion_score_mean', 0):.3f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            best_performance = {"normalized_completion_score": 0.7 + stage_id*0.1}
            model_state = {"stage_model": torch.randn(32, 16)}
            training_config = {"learning_rate": 0.001, "batch_size": 128}
            
            config_manager.save_best_model(stage_id, model_state, best_performance, training_config)
            print(f"   ğŸ’¾ é˜¶æ®µ {stage_id} æœ€ä½³æ¨¡å‹å·²ä¿å­˜")
        
        print("   âœ… é˜¶æ®µé…ç½®ç®¡ç†å®Œæˆ")
        
        # 4. æ¼”ç¤ºè®­ç»ƒé…ç½®å¢å¼º
        print("\n4ï¸âƒ£ è®­ç»ƒé…ç½®å¢å¼ºæ¼”ç¤º")
        print("-" * 40)
        
        base_config = {
            "env": "UAVTaskEnv",
            "num_workers": 4,
            "lr": 0.001,
            "train_batch_size": 4000
        }
        
        enhanced_config = create_training_config_with_logging(
            base_config,
            log_dir=demo_dir,
            experiment_name="demo_experiment"
        )
        
        print("   ğŸ“‹ åŸºç¡€é…ç½®:")
        for key, value in base_config.items():
            print(f"      {key}: {value}")
        
        print("   â• å¢å¼ºé…ç½®æ·»åŠ :")
        added_keys = set(enhanced_config.keys()) - set(base_config.keys())
        for key in sorted(added_keys):
            if key != "callbacks":  # callbacksæ˜¯ç±»ï¼Œä¸é€‚åˆç›´æ¥æ‰“å°
                print(f"      {key}: {enhanced_config[key]}")
            else:
                print(f"      {key}: CurriculumTrainingCallbacks")
        
        print("   âœ… è®­ç»ƒé…ç½®å¢å¼ºå®Œæˆ")
        
        # 5. å±•ç¤ºä¿å­˜çš„æ–‡ä»¶
        print("\n5ï¸âƒ£ ç”Ÿæˆçš„æ–‡ä»¶å±•ç¤º")
        print("-" * 40)
        
        # ä¿å­˜æ‰€æœ‰æ•°æ®
        logger.save_training_history()
        checkpoint_manager.save_checkpoint_history()
        config_manager.save_all_data()
        
        # åˆ—å‡ºç”Ÿæˆçš„æ–‡ä»¶
        def list_files_recursive(directory, prefix=""):
            items = []
            try:
                for item in sorted(Path(directory).iterdir()):
                    if item.is_file():
                        size = item.stat().st_size
                        items.append(f"{prefix}ğŸ“„ {item.name} ({size} bytes)")
                    elif item.is_dir():
                        items.append(f"{prefix}ğŸ“ {item.name}/")
                        items.extend(list_files_recursive(item, prefix + "  "))
            except PermissionError:
                items.append(f"{prefix}âŒ æƒé™ä¸è¶³")
            return items
        
        print("   ğŸ“‚ ç”Ÿæˆçš„æ–‡ä»¶ç»“æ„:")
        file_list = list_files_recursive(demo_dir, "   ")
        for file_info in file_list[:20]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
            print(file_info)
        
        if len(file_list) > 20:
            print(f"   ... è¿˜æœ‰ {len(file_list) - 20} ä¸ªæ–‡ä»¶")
        
        print("   âœ… æ–‡ä»¶ç”Ÿæˆå®Œæˆ")
        
        # 6. åŠŸèƒ½éªŒè¯æ€»ç»“
        print("\n6ï¸âƒ£ åŠŸèƒ½éªŒè¯æ€»ç»“")
        print("-" * 40)
        
        verification_results = []
        
        # éªŒè¯TensorBoardæ—¥å¿—
        history_file = Path(demo_dir) / "demo_experiment_history.json"
        if history_file.exists():
            verification_results.append("âœ… TensorBoardè®­ç»ƒå†å²ä¿å­˜")
        else:
            verification_results.append("âŒ TensorBoardè®­ç»ƒå†å²ä¿å­˜")
        
        # éªŒè¯æ£€æŸ¥ç‚¹
        checkpoint_dir = Path(demo_dir) / "checkpoints"
        if checkpoint_dir.exists() and any(checkpoint_dir.glob("*.pt")):
            verification_results.append("âœ… æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜")
        else:
            verification_results.append("âŒ æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜")
        
        # éªŒè¯é…ç½®æ–‡ä»¶
        config_dir = Path(demo_dir) / "configs"
        if config_dir.exists() and any(config_dir.glob("*.json")):
            verification_results.append("âœ… é˜¶æ®µé…ç½®ä¿å­˜")
        else:
            verification_results.append("âŒ é˜¶æ®µé…ç½®ä¿å­˜")
        
        # éªŒè¯TensorBoardç›®å½•
        tensorboard_dir = Path(demo_dir) / "tensorboard"
        if tensorboard_dir.exists():
            verification_results.append("âœ… TensorBoardæ—¥å¿—ç›®å½•åˆ›å»º")
        else:
            verification_results.append("âŒ TensorBoardæ—¥å¿—ç›®å½•åˆ›å»º")
        
        for result in verification_results:
            print(f"   {result}")
        
        # æ¸…ç†èµ„æº
        logger.close()
        
        print("\nğŸ‰ ä»»åŠ¡14åŠŸèƒ½æ¼”ç¤ºå®Œæˆï¼")
        print("   æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½å‡æ­£å¸¸å·¥ä½œï¼Œç³»ç»Ÿå·²å‡†å¤‡å¥½æŠ•å…¥ä½¿ç”¨ã€‚")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False
        
    finally:
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        try:
            shutil.rmtree(demo_dir, ignore_errors=True)
            print(f"\nğŸ§¹ ä¸´æ—¶ç›®å½•å·²æ¸…ç†: {demo_dir}")
        except:
            print(f"\nâš ï¸  ä¸´æ—¶ç›®å½•æ¸…ç†å¤±è´¥: {demo_dir}")


if __name__ == "__main__":
    success = demonstrate_task14_functionality()
    if success:
        print("\nâœ¨ æ¼”ç¤ºæˆåŠŸå®Œæˆï¼ä»»åŠ¡14çš„è®­ç»ƒæ•°æ®ä¿å­˜ä¸TensorBoardé›†æˆåŠŸèƒ½å®Œå…¨æ­£å¸¸ã€‚")
    else:
        print("\nğŸ’¥ æ¼”ç¤ºè¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç›¸å…³æ¨¡å—ã€‚")
    
    sys.exit(0 if success else 1)