{
  "scenario_name": "test_model_loading_priority",
  "network_type": "DeepFCNResidual",
  "training_time": 2.656827211380005,
  "task_assignments_count": 4,
  "evaluation_metrics": {
    "completion_rate": 0.5,
    "satisfied_targets_rate": 0.5,
    "target_satisfaction_rate": 0.5,
    "resource_satisfaction_rate": 0.5,
    "resource_utilization_rate": 0.5,
    "total_reward_score": 750.0,
    "marginal_utility_score": 0.0,
    "resource_efficiency_score": 500.0,
    "distance_cost_score": -0.0,
    "target_completion_score": 250.0,
    "completion_bonus": 0,
    "completed_targets_count": 1,
    "total_targets_count": 2,
    "total_contribution": 6.0,
    "total_demand": 12,
    "total_initial_supply": 12
  },
  "training_statistics": {
    "reward_mean": -221.50330476215635,
    "reward_std": 444.00463753302375,
    "reward_max": 441.83985143313794,
    "reward_min": -852.1311470702044,
    "reward_final": -650.5706535674278,
    "reward_improvement": 7.69415417793914,
    "loss_mean": 1569.3289846401024,
    "loss_std": 1579.65120440726,
    "loss_final": 3357.455596923828,
    "loss_min": 0.0
  },
  "training_history_summary": {
    "total_episodes": 10,
    "final_reward": -650.5706535674278,
    "final_loss": 3357.455596923828,
    "final_epsilon": 0.8559991174191948,
    "final_completion_rate": 0.7083333333333333
  },
  "config_summary": {
    "episodes": 20,
    "learning_rate": 0.0001,
    "batch_size": 64,
    "gamma": 0.99,
    "epsilon_start": 0.9,
    "epsilon_end": 0.1,
    "epsilon_decay": 0.9995
  }
}