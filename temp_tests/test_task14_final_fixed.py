"""
ä»»åŠ¡14æœ€ç»ˆç»¼åˆæµ‹è¯• - ä¿®å¤ç‰ˆ
æµ‹è¯•è®­ç»ƒæ•°æ®ä¿å­˜ä¸TensorBoardé›†æˆçš„å®Œæ•´åŠŸèƒ½
"""

import os
import sys
import unittest
import tempfile
import shutil
import torch
import numpy as np
import json
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥æ‰€æœ‰æ ¸å¿ƒæ¨¡å—
from training_logger import (
    CurriculumTensorBoardLogger, 
    ModelCheckpointManager, 
    create_training_config_with_logging
)
from stage_config_manager import StageConfig, StageConfigManager


class TestTask14CoreFunctionality(unittest.TestCase):
    """ä»»åŠ¡14æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.test_dir = tempfile.mkdtemp()
        print(f"æµ‹è¯•ç›®å½•: {self.test_dir}")
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        shutil.rmtree(self.test_dir, ignore_errors=True)
    
    def test_tensorboard_logger_core_features(self):
        """æµ‹è¯•TensorBoardæ—¥å¿—è®°å½•å™¨æ ¸å¿ƒåŠŸèƒ½"""
        print("\\nğŸ§ª æµ‹è¯•TensorBoardæ—¥å¿—è®°å½•å™¨æ ¸å¿ƒåŠŸèƒ½...")
        
        # åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
        logger = CurriculumTensorBoardLogger(self.test_dir, "core_test")
        
        try:
            # 1. æµ‹è¯•å°ºåº¦ä¸å˜æŒ‡æ ‡è®°å½•
            metrics = {
                "per_agent_reward": 12.5,
                "normalized_completion_score": 0.85,
                "efficiency_metric": 0.42
            }
            logger.log_scale_invariant_metrics(metrics, 1000, 1, 5, 3)
            
            # éªŒè¯æŒ‡æ ‡è®°å½•
            self.assertEqual(len(logger.training_history["metrics"]), 1)
            metric_record = logger.training_history["metrics"][0]
            self.assertEqual(metric_record["per_agent_reward"], 12.5)
            self.assertEqual(metric_record["normalized_completion_score"], 0.85)
            
            # 2. æµ‹è¯•é˜¶æ®µåˆ‡æ¢è®°å½•
            logger.log_stage_transition(0, 1, 1000, "performance_threshold")
            
            # éªŒè¯é˜¶æ®µåˆ‡æ¢è®°å½•
            self.assertEqual(len(logger.training_history["stage_transitions"]), 1)
            transition = logger.training_history["stage_transitions"][0]
            self.assertEqual(transition["from_stage"], 0)
            self.assertEqual(transition["to_stage"], 1)
            
            # 3. æµ‹è¯•å›é€€äº‹ä»¶è®°å½•
            logger.log_rollback_event(1, 2000, 0.15, 0.1)
            
            # éªŒè¯å›é€€äº‹ä»¶è®°å½•
            self.assertEqual(len(logger.training_history["rollback_events"]), 1)
            rollback = logger.training_history["rollback_events"][0]
            self.assertEqual(rollback["performance_drop"], 0.15)
            
            # 4. æµ‹è¯•è®­ç»ƒå†å²ä¿å­˜
            logger.save_training_history()
            history_file = Path(self.test_dir) / "core_test_history.json"
            self.assertTrue(history_file.exists())
            
            print("âœ… TensorBoardæ—¥å¿—è®°å½•å™¨æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•é€šè¿‡")
            
        finally:
            logger.close()
    
    def test_model_checkpoint_manager_features(self):
        """æµ‹è¯•æ¨¡å‹æ£€æŸ¥ç‚¹ç®¡ç†å™¨åŠŸèƒ½"""
        print("\\nğŸ§ª æµ‹è¯•æ¨¡å‹æ£€æŸ¥ç‚¹ç®¡ç†å™¨åŠŸèƒ½...")
        
        checkpoint_manager = ModelCheckpointManager(
            os.path.join(self.test_dir, "checkpoints"), 
            max_checkpoints=3
        )
        
        # 1. æµ‹è¯•æ£€æŸ¥ç‚¹ä¿å­˜
        for i in range(5):
            model_state = {"layer1.weight": torch.randn(10, 5)}
            optimizer_state = {"lr": 0.001}
            metrics = {"normalized_completion_score": 0.7 + i * 0.05}
            
            is_best = (i == 3)  # ç¬¬4ä¸ªæ˜¯æœ€ä½³çš„
            checkpoint_path = checkpoint_manager.save_checkpoint(
                model_state, optimizer_state, metrics, 
                i*1000, 1, is_best
            )
            
            self.assertTrue(os.path.exists(checkpoint_path))
        
        # 2. æµ‹è¯•æœ€ä½³æ£€æŸ¥ç‚¹è·å–
        best_checkpoint = checkpoint_manager.get_best_checkpoint()
        self.assertIsNotNone(best_checkpoint)
        
        # éªŒè¯æœ€ä½³æ£€æŸ¥ç‚¹
        loaded_data = checkpoint_manager.load_checkpoint(best_checkpoint)
        self.assertEqual(loaded_data["metrics"]["normalized_completion_score"], 0.85)
        
        print("âœ… æ¨¡å‹æ£€æŸ¥ç‚¹ç®¡ç†å™¨åŠŸèƒ½æµ‹è¯•é€šè¿‡")
    
    def test_stage_config_manager_features(self):
        """æµ‹è¯•é˜¶æ®µé…ç½®ç®¡ç†å™¨åŠŸèƒ½"""
        print("\\nğŸ§ª æµ‹è¯•é˜¶æ®µé…ç½®ç®¡ç†å™¨åŠŸèƒ½...")
        
        config_manager = StageConfigManager(os.path.join(self.test_dir, "configs"))
        
        # 1. æµ‹è¯•é»˜è®¤é…ç½®åŠ è½½
        self.assertGreater(len(config_manager.stage_configs), 0)
        
        config_0 = config_manager.get_stage_config(0)
        self.assertIsNotNone(config_0)
        self.assertEqual(config_0.stage_id, 0)
        
        # 2. æµ‹è¯•é…ç½®æ›´æ–°
        config_manager.update_stage_config(0, learning_rate=0.002)
        
        updated_config = config_manager.get_stage_config(0)
        self.assertEqual(updated_config.learning_rate, 0.002)
        
        # 3. æµ‹è¯•æ€§èƒ½è®°å½•
        for i in range(10):
            performance = {
                "per_agent_reward": 10 + i,
                "normalized_completion_score": 0.7 + i * 0.02,
                "efficiency_metric": 0.3 + i * 0.01
            }
            config_manager.record_stage_performance(0, performance, i, i*100)
        
        # 4. æµ‹è¯•æ€§èƒ½æ‘˜è¦
        summary = config_manager.get_stage_performance_summary(0)
        self.assertEqual(summary["total_records"], 10)
        self.assertIn("per_agent_reward_mean", summary)
        
        print("âœ… é˜¶æ®µé…ç½®ç®¡ç†å™¨åŠŸèƒ½æµ‹è¯•é€šè¿‡")


class TestTask14IntegrationWorkflow(unittest.TestCase):
    """ä»»åŠ¡14é›†æˆå·¥ä½œæµæµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.test_dir = tempfile.mkdtemp()
        print(f"é›†æˆæµ‹è¯•ç›®å½•: {self.test_dir}")
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        shutil.rmtree(self.test_dir, ignore_errors=True)
    
    def test_complete_workflow(self):
        """æµ‹è¯•å®Œæ•´å·¥ä½œæµ"""
        print("\\nğŸ”„ æµ‹è¯•å®Œæ•´çš„è¯¾ç¨‹å­¦ä¹ è®­ç»ƒå·¥ä½œæµ...")
        
        # 1. åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶
        logger = CurriculumTensorBoardLogger(self.test_dir, "workflow_test")
        checkpoint_manager = ModelCheckpointManager(
            os.path.join(self.test_dir, "checkpoints")
        )
        config_manager = StageConfigManager(
            os.path.join(self.test_dir, "configs")
        )
        
        try:
            # 2. æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
            for step in range(0, 2000, 200):
                stage = step // 600
                
                # ç”Ÿæˆæ¨¡æ‹ŸæŒ‡æ ‡
                metrics = {
                    "per_agent_reward": 10 + stage + np.random.normal(0, 0.5),
                    "normalized_completion_score": 0.7 + stage * 0.05 + np.random.uniform(-0.05, 0.1),
                    "efficiency_metric": 0.3 + stage * 0.02 + np.random.uniform(-0.02, 0.05)
                }
                
                # è®°å½•åˆ°æ—¥å¿—
                n_uavs = 3 + stage
                n_targets = 2 + stage
                logger.log_scale_invariant_metrics(metrics, step, stage, n_uavs, n_targets)
                
                # è®°å½•åˆ°é…ç½®ç®¡ç†å™¨
                episode = step // 200
                config_manager.record_stage_performance(stage, metrics, episode, step)
                
                # ä¿å­˜æ£€æŸ¥ç‚¹
                if step % 400 == 0:
                    model_state = {"layer1.weight": torch.randn(10, 5)}
                    optimizer_state = {"lr": 0.001}
                    
                    is_best = metrics["normalized_completion_score"] > 0.8
                    checkpoint_manager.save_checkpoint(
                        model_state, optimizer_state, metrics,
                        step, stage, is_best
                    )
                
                # è®°å½•é˜¶æ®µåˆ‡æ¢
                if step in [600, 1200]:
                    logger.log_stage_transition(stage-1, stage, step, "performance_threshold")
            
            # 3. éªŒè¯ç»“æœ
            print("   éªŒè¯å·¥ä½œæµç»“æœ...")
            
            # éªŒè¯æ—¥å¿—è®°å½•
            self.assertGreater(len(logger.training_history["metrics"]), 0)
            
            # éªŒè¯æ£€æŸ¥ç‚¹
            self.assertGreater(len(checkpoint_manager.checkpoint_history), 0)
            
            # 4. ä¿å­˜æ‰€æœ‰æ•°æ®
            logger.save_training_history()
            checkpoint_manager.save_checkpoint_history()
            config_manager.save_all_data()
            
            # éªŒè¯æ–‡ä»¶å­˜åœ¨
            history_file = Path(self.test_dir) / "workflow_test_history.json"
            self.assertTrue(history_file.exists())
            
            print("âœ… å®Œæ•´çš„è¯¾ç¨‹å­¦ä¹ è®­ç»ƒå·¥ä½œæµæµ‹è¯•é€šè¿‡")
            
        finally:
            logger.close()


def run_task14_final_tests():
    """è¿è¡Œä»»åŠ¡14æœ€ç»ˆæµ‹è¯•"""
    print("ğŸš€ å¼€å§‹ä»»åŠ¡14æœ€ç»ˆç»¼åˆæµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•æ¨¡å—å¯¼å…¥
    print("\\nğŸ“¦ æµ‹è¯•æ¨¡å—å¯¼å…¥...")
    try:
        from training_logger import CurriculumTensorBoardLogger
        from stage_config_manager import StageConfigManager
        print("âœ… æ‰€æœ‰æ ¸å¿ƒæ¨¡å—å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestSuite()
    
    # æ·»åŠ æµ‹è¯•ç±»
    test_classes = [
        TestTask14CoreFunctionality,
        TestTask14IntegrationWorkflow
    ]
    
    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        test_suite.addTests(tests)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=1)
    result = runner.run(test_suite)
    
    # è¾“å‡ºè¯¦ç»†ç»“æœ
    print("\\n" + "=" * 60)
    print("ğŸ“‹ ä»»åŠ¡14æœ€ç»ˆæµ‹è¯•ç»“æœæŠ¥å‘Š")
    print("=" * 60)
    
    print(f"æ€»æµ‹è¯•æ•°: {result.testsRun}")
    print(f"æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"å¤±è´¥: {len(result.failures)}")
    print(f"é”™è¯¯: {len(result.errors)}")
    
    if result.failures:
        print("\\nâŒ å¤±è´¥çš„æµ‹è¯•:")
        for failure in result.failures:
            print(f"   - {failure[0]}")
    
    if result.errors:
        print("\\nğŸ’¥ é”™è¯¯çš„æµ‹è¯•:")
        for error in result.errors:
            print(f"   - {error[0]}")
    
    # åŠŸèƒ½éªŒè¯æ€»ç»“
    success = result.wasSuccessful()
    
    print("\\nğŸ¯ ä»»åŠ¡14åŠŸèƒ½éªŒè¯æ€»ç»“:")
    print(f"   TensorBoardé›†æˆ: {'âœ… é€šè¿‡' if success else 'âŒ éƒ¨åˆ†å¤±è´¥'}")
    print(f"   è®­ç»ƒæ•°æ®ä¿å­˜: {'âœ… é€šè¿‡' if success else 'âŒ éƒ¨åˆ†å¤±è´¥'}")
    print(f"   å°ºåº¦ä¸å˜æŒ‡æ ‡: {'âœ… é€šè¿‡' if success else 'âŒ éƒ¨åˆ†å¤±è´¥'}")
    print(f"   è¯¾ç¨‹å­¦ä¹ å¯è§†åŒ–: {'âœ… é€šè¿‡' if success else 'âŒ éƒ¨åˆ†å¤±è´¥'}")
    print(f"   æ¨¡å‹æ£€æŸ¥ç‚¹ç®¡ç†: {'âœ… é€šè¿‡' if success else 'âŒ éƒ¨åˆ†å¤±è´¥'}")
    print(f"   é˜¶æ®µé…ç½®ç®¡ç†: {'âœ… é€šè¿‡' if success else 'âŒ éƒ¨åˆ†å¤±è´¥'}")
    
    if success:
        print("\\nğŸ‰ æ­å–œï¼ä»»åŠ¡14çš„æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        print("   âœ¨ è®­ç»ƒæ•°æ®ä¿å­˜ä¸TensorBoardé›†æˆåŠŸèƒ½å®Œå…¨æ­£å¸¸")
        print("   âœ¨ å°ºåº¦ä¸å˜æŒ‡æ ‡è®°å½•å‡†ç¡®æ— è¯¯")
        print("   âœ¨ è¯¾ç¨‹å­¦ä¹ è¿›åº¦å¯è§†åŒ–å®Œæ•´")
        print("   âœ¨ æ¨¡å‹æ£€æŸ¥ç‚¹ç®¡ç†é«˜æ•ˆå¯é ")
    else:
        print("\\nâš ï¸ éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œä½†æ ¸å¿ƒåŠŸèƒ½åŸºæœ¬æ­£å¸¸")
        print("   å»ºè®®æ£€æŸ¥å¤±è´¥çš„æµ‹è¯•é¡¹å¹¶è¿›è¡Œä¼˜åŒ–")
    
    return success


if __name__ == "__main__":
    success = run_task14_final_tests()
    sys.exit(0 if success else 1)