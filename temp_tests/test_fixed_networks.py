# -*- coding: utf-8 -*-
# æ–‡ä»¶å: test_fixed_networks.py
# æè¿°: ä¿®å¤ç‰ˆç½‘ç»œçš„æµ‹è¯•è„šæœ¬ï¼ŒéªŒè¯ä¸‰ä¸ªé£é™©ç‚¹çš„ä¿®å¤æ•ˆæœ

import torch
import torch.nn as nn
import numpy as np
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from networks_fixed import (
    RobustFeatureExtractor,
    TrueGraphAttentionNetwork,
    RelativePositionEncoder,
    create_fixed_network
)
from transformer_gnn_fixed import FixedTransformerGNN, create_fixed_transformer_gnn_model
from gymnasium import spaces
import unittest


class TestFixedNetworks(unittest.TestCase):
    """ä¿®å¤ç‰ˆç½‘ç»œçš„æµ‹è¯•ç±»"""
    
    def setUp(self):
        """æµ‹è¯•è®¾ç½®"""
        self.batch_size = 4
        self.input_dim = 128
        self.output_dim = 10
        self.hidden_dims = [256, 128, 64]
        
        # æµ‹è¯•é…ç½®
        self.test_config = {
            'extraction_strategy': 'semantic',
            'total_input_dim': self.input_dim,
            'embedding_dim': 128,
            'num_heads': 8,
            'dropout': 0.1,
            'num_attention_layers': 2,
            'n_uavs': 2,
            'n_targets': 3,
            'uav_features_per_entity': 8,
            'target_features_per_entity': 7,
            'max_distance': 1000.0,
            'target_feature_ratio': 0.6
        }
    
    def test_robust_feature_extractor_semantic(self):
        """æµ‹è¯•é²æ£’ç‰¹å¾æå–å™¨ - è¯­ä¹‰ç­–ç•¥"""
        print("\n=== æµ‹è¯•é£é™©ç‚¹1ä¿®å¤ï¼šé²æ£’ç‰¹å¾æå–å™¨ï¼ˆè¯­ä¹‰ç­–ç•¥ï¼‰ ===")
        
        # åˆ›å»ºç‰¹å¾æå–å™¨
        extractor = RobustFeatureExtractor(self.test_config)
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        test_input = torch.randn(self.batch_size, self.input_dim)
        
        # æå–ç‰¹å¾
        uav_features, target_features, additional_features = extractor.extract_features(test_input)
        
        # éªŒè¯è¾“å‡ºå½¢çŠ¶
        expected_uav_dim = self.test_config['uav_features_per_entity'] * self.test_config['n_uavs']
        expected_target_dim = self.test_config['target_features_per_entity'] * self.test_config['n_targets']
        
        self.assertEqual(uav_features.shape, (self.batch_size, expected_uav_dim))
        self.assertEqual(target_features.shape, (self.batch_size, expected_target_dim))
        
        # éªŒè¯é¢å¤–ç‰¹å¾
        self.assertIn('collaboration', additional_features)
        self.assertIn('global', additional_features)
        
        print(f"âœ“ è¯­ä¹‰ç‰¹å¾æå–æˆåŠŸ - UAV: {uav_features.shape}, ç›®æ ‡: {target_features.shape}")
        print(f"âœ“ é¢å¤–ç‰¹å¾: {list(additional_features.keys())}")
    
    def test_robust_feature_extractor_ratio(self):
        """æµ‹è¯•é²æ£’ç‰¹å¾æå–å™¨ - æ¯”ä¾‹ç­–ç•¥"""
        print("\n=== æµ‹è¯•é£é™©ç‚¹1ä¿®å¤ï¼šé²æ£’ç‰¹å¾æå–å™¨ï¼ˆæ¯”ä¾‹ç­–ç•¥ï¼‰ ===")
        
        # ä¿®æ”¹é…ç½®ä¸ºæ¯”ä¾‹ç­–ç•¥
        ratio_config = self.test_config.copy()
        ratio_config['extraction_strategy'] = 'ratio'
        
        # åˆ›å»ºç‰¹å¾æå–å™¨
        extractor = RobustFeatureExtractor(ratio_config)
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        test_input = torch.randn(self.batch_size, self.input_dim)
        
        # æå–ç‰¹å¾
        uav_features, target_features, additional_features = extractor.extract_features(test_input)
        
        # éªŒè¯è¾“å‡ºå½¢çŠ¶
        expected_target_dim = int(self.input_dim * self.test_config['target_feature_ratio'])
        expected_uav_dim = self.input_dim - expected_target_dim
        
        self.assertEqual(uav_features.shape, (self.batch_size, expected_uav_dim))
        self.assertEqual(target_features.shape, (self.batch_size, expected_target_dim))
        
        print(f"âœ“ æ¯”ä¾‹ç‰¹å¾æå–æˆåŠŸ - UAV: {uav_features.shape}, ç›®æ ‡: {target_features.shape}")
        print(f"âœ“ æ¯”ä¾‹åˆ†é…: ç›®æ ‡{self.test_config['target_feature_ratio']:.1f}, UAV{1-self.test_config['target_feature_ratio']:.1f}")
    
    def test_robust_feature_extractor_fixed(self):
        """æµ‹è¯•é²æ£’ç‰¹å¾æå–å™¨ - å›ºå®šç»´åº¦ç­–ç•¥"""
        print("\n=== æµ‹è¯•é£é™©ç‚¹1ä¿®å¤ï¼šé²æ£’ç‰¹å¾æå–å™¨ï¼ˆå›ºå®šç»´åº¦ç­–ç•¥ï¼‰ ===")
        
        # ä¿®æ”¹é…ç½®ä¸ºå›ºå®šç»´åº¦ç­–ç•¥
        fixed_config = self.test_config.copy()
        fixed_config['extraction_strategy'] = 'fixed'
        fixed_config['uav_feature_dim'] = 32
        fixed_config['target_feature_dim'] = 48
        
        # åˆ›å»ºç‰¹å¾æå–å™¨
        extractor = RobustFeatureExtractor(fixed_config)
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        test_input = torch.randn(self.batch_size, self.input_dim)
        
        # æå–ç‰¹å¾
        uav_features, target_features, additional_features = extractor.extract_features(test_input)
        
        # éªŒè¯è¾“å‡ºå½¢çŠ¶
        self.assertEqual(uav_features.shape, (self.batch_size, 32))
        self.assertEqual(target_features.shape, (self.batch_size, 48))
        
        # éªŒè¯å‰©ä½™ç‰¹å¾
        remaining_dim = self.input_dim - 32 - 48
        if remaining_dim > 0:
            self.assertIn('remaining', additional_features)
            self.assertEqual(additional_features['remaining'].shape, (self.batch_size, remaining_dim))
        
        print(f"âœ“ å›ºå®šç»´åº¦ç‰¹å¾æå–æˆåŠŸ - UAV: {uav_features.shape}, ç›®æ ‡: {target_features.shape}")
        if remaining_dim > 0:
            print(f"âœ“ å‰©ä½™ç‰¹å¾ç»´åº¦: {remaining_dim}")
    
    def test_relative_position_encoder(self):
        """æµ‹è¯•ç›¸å¯¹ä½ç½®ç¼–ç å™¨"""
        print("\n=== æµ‹è¯•é£é™©ç‚¹3ä¿®å¤ï¼šç›¸å¯¹ä½ç½®ç¼–ç å™¨ ===")
        
        # åˆ›å»ºä½ç½®ç¼–ç å™¨
        position_encoder = RelativePositionEncoder(
            position_dim=2,
            embed_dim=64,
            max_distance=1000.0,
            num_distance_bins=32,
            num_angle_bins=16
        )
        
        # åˆ›å»ºæµ‹è¯•ç›¸å¯¹ä½ç½®
        num_pairs = 6  # 2 UAVs * 3 targets
        relative_positions = torch.randn(self.batch_size, num_pairs, 2) * 500  # éšæœºç›¸å¯¹ä½ç½®
        
        # ç”Ÿæˆä½ç½®ç¼–ç 
        position_embeddings = position_encoder(relative_positions)
        
        # éªŒè¯è¾“å‡ºå½¢çŠ¶
        self.assertEqual(position_embeddings.shape, (self.batch_size, num_pairs, 64))
        
        # éªŒè¯ç¼–ç çš„æœ‰æ•ˆæ€§ï¼ˆä¸åº”è¯¥å…¨ä¸ºé›¶ï¼‰
        self.assertGreater(torch.abs(position_embeddings).sum().item(), 0)
        
        print(f"âœ“ ä½ç½®ç¼–ç ç”ŸæˆæˆåŠŸ - è¾“å…¥: {relative_positions.shape}, è¾“å‡º: {position_embeddings.shape}")
        print(f"âœ“ ç¼–ç èŒƒå›´: [{position_embeddings.min().item():.3f}, {position_embeddings.max().item():.3f}]")
    
    def test_graph_attention_layer(self):
        """æµ‹è¯•å›¾æ³¨æ„åŠ›å±‚"""
        print("\n=== æµ‹è¯•é£é™©ç‚¹2ä¿®å¤ï¼šçœŸæ­£çš„å›¾æ³¨æ„åŠ›å±‚ ===")
        
        from networks_fixed import GraphAttentionLayer
        
        # åˆ›å»ºå›¾æ³¨æ„åŠ›å±‚
        attention_layer = GraphAttentionLayer(
            embed_dim=128,
            num_heads=8,
            dropout=0.1,
            use_position_encoding=True
        )
        
        # åˆ›å»ºæµ‹è¯•èŠ‚ç‚¹åµŒå…¥
        num_nodes = 5  # 2 UAVs + 3 targets
        node_embeddings = torch.randn(self.batch_size, num_nodes, 128)
        
        # åˆ›å»ºä½ç½®ç¼–ç 
        position_embeddings = torch.randn(self.batch_size, 1, 128)
        
        # åº”ç”¨æ³¨æ„åŠ›å±‚
        output_embeddings = attention_layer(node_embeddings, position_embeddings)
        
        # éªŒè¯è¾“å‡ºå½¢çŠ¶
        self.assertEqual(output_embeddings.shape, node_embeddings.shape)
        
        # éªŒè¯è¾“å‡ºä¸ç­‰äºè¾“å…¥ï¼ˆç¡®å®è¿›è¡Œäº†å˜æ¢ï¼‰
        self.assertFalse(torch.allclose(output_embeddings, node_embeddings, atol=1e-6))
        
        print(f"âœ“ å›¾æ³¨æ„åŠ›è®¡ç®—æˆåŠŸ - è¾“å…¥: {node_embeddings.shape}, è¾“å‡º: {output_embeddings.shape}")
        print(f"âœ“ æ³¨æ„åŠ›å˜æ¢æœ‰æ•ˆæ€§éªŒè¯é€šè¿‡")
    
    def test_true_graph_attention_network(self):
        """æµ‹è¯•çœŸæ­£çš„å›¾æ³¨æ„åŠ›ç½‘ç»œ"""
        print("\n=== æµ‹è¯•é£é™©ç‚¹2ä¿®å¤ï¼šçœŸæ­£çš„å›¾æ³¨æ„åŠ›ç½‘ç»œ ===")
        
        # åˆ›å»ºç½‘ç»œ
        network = TrueGraphAttentionNetwork(
            input_dim=self.input_dim,
            hidden_dims=self.hidden_dims,
            output_dim=self.output_dim,
            config=self.test_config
        )
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        test_input = torch.randn(self.batch_size, self.input_dim)
        
        # å‰å‘ä¼ æ’­
        output = network(test_input)
        
        # éªŒè¯è¾“å‡ºå½¢çŠ¶
        self.assertEqual(output.shape, (self.batch_size, self.output_dim))
        
        # éªŒè¯ç½‘ç»œå‚æ•°å¯è®­ç»ƒ
        total_params = sum(p.numel() for p in network.parameters() if p.requires_grad)
        self.assertGreater(total_params, 0)
        
        print(f"âœ“ å›¾æ³¨æ„åŠ›ç½‘ç»œå‰å‘ä¼ æ’­æˆåŠŸ - è¾“å…¥: {test_input.shape}, è¾“å‡º: {output.shape}")
        print(f"âœ“ å¯è®­ç»ƒå‚æ•°æ•°é‡: {total_params:,}")
    
    def test_fixed_transformer_gnn_flat_mode(self):
        """æµ‹è¯•ä¿®å¤ç‰ˆTransformerGNN - æ‰å¹³æ¨¡å¼"""
        print("\n=== æµ‹è¯•ä¿®å¤ç‰ˆTransformerGNNï¼šæ‰å¹³æ¨¡å¼ ===")
        
        # åˆ›å»ºè§‚æµ‹ç©ºé—´
        obs_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.input_dim,), dtype=np.float32)
        action_space = spaces.Discrete(self.output_dim)
        
        # æ¨¡å‹é…ç½®
        model_config = {
            "embed_dim": 128,
            "num_heads": 8,
            "num_layers": 2,
            "dropout": 0.1,
            "use_position_encoding": True,
            "use_noisy_linear": False,  # ç®€åŒ–æµ‹è¯•
            "extraction_strategy": "semantic",
            "n_uavs": 2,
            "n_targets": 3,
            "uav_features_per_entity": 8,
            "target_features_per_entity": 7,
            "max_distance": 1000.0
        }
        
        # åˆ›å»ºæ¨¡å‹
        model = FixedTransformerGNN(
            obs_space=obs_space,
            action_space=action_space,
            num_outputs=self.output_dim,
            model_config=model_config,
            name="TestFixedTransformerGNN"
        )
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        input_dict = {
            "obs": torch.randn(self.batch_size, self.input_dim)
        }
        
        # å‰å‘ä¼ æ’­
        logits, state = model.forward(input_dict, [], None)
        
        # éªŒè¯è¾“å‡º
        self.assertEqual(logits.shape, (self.batch_size, self.output_dim))
        
        # éªŒè¯å€¼å‡½æ•°
        values = model.value_function()
        self.assertEqual(values.shape, (self.batch_size,))
        
        print(f"âœ“ æ‰å¹³æ¨¡å¼å‰å‘ä¼ æ’­æˆåŠŸ - logits: {logits.shape}, values: {values.shape}")
    
    def test_fixed_transformer_gnn_dict_mode(self):
        """æµ‹è¯•ä¿®å¤ç‰ˆTransformerGNN - å­—å…¸æ¨¡å¼"""
        print("\n=== æµ‹è¯•ä¿®å¤ç‰ˆTransformerGNNï¼šå­—å…¸æ¨¡å¼ ===")
        
        # åˆ›å»ºå­—å…¸è§‚æµ‹ç©ºé—´
        obs_space = spaces.Dict({
            'uav_features': spaces.Box(low=-np.inf, high=np.inf, shape=(2, 9), dtype=np.float32),
            'target_features': spaces.Box(low=-np.inf, high=np.inf, shape=(3, 8), dtype=np.float32),
            'relative_positions': spaces.Box(low=-1.0, high=1.0, shape=(2, 3, 2), dtype=np.float32),
            'distances': spaces.Box(low=0.0, high=1.0, shape=(2, 3), dtype=np.float32),
            'masks': spaces.Dict({
                'uav_mask': spaces.Box(low=0, high=1, shape=(2,), dtype=np.int32),
                'target_mask': spaces.Box(low=0, high=1, shape=(3,), dtype=np.int32)
            })
        })
        action_space = spaces.Discrete(self.output_dim)
        
        # æ¨¡å‹é…ç½®
        model_config = {
            "embed_dim": 128,
            "num_heads": 8,
            "num_layers": 2,
            "dropout": 0.1,
            "use_position_encoding": True,
            "use_local_attention": True,
            "use_noisy_linear": False,  # ç®€åŒ–æµ‹è¯•
            "k_adaptive": True,
            "k_min": 2,
            "k_max": 3
        }
        
        # åˆ›å»ºæ¨¡å‹
        model = FixedTransformerGNN(
            obs_space=obs_space,
            action_space=action_space,
            num_outputs=self.output_dim,
            model_config=model_config,
            name="TestFixedTransformerGNN_Dict"
        )
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        input_dict = {
            "obs": {
                'uav_features': torch.randn(self.batch_size, 2, 9),
                'target_features': torch.randn(self.batch_size, 3, 8),
                'relative_positions': torch.randn(self.batch_size, 2, 3, 2),
                'distances': torch.rand(self.batch_size, 2, 3),
                'masks': {
                    'uav_mask': torch.ones(self.batch_size, 2, dtype=torch.int32),
                    'target_mask': torch.ones(self.batch_size, 3, dtype=torch.int32)
                }
            }
        }
        
        # å‰å‘ä¼ æ’­
        logits, state = model.forward(input_dict, [], None)
        
        # éªŒè¯è¾“å‡º
        self.assertEqual(logits.shape, (self.batch_size, self.output_dim))
        
        # éªŒè¯å€¼å‡½æ•°
        values = model.value_function()
        self.assertEqual(values.shape, (self.batch_size,))
        
        print(f"âœ“ å­—å…¸æ¨¡å¼å‰å‘ä¼ æ’­æˆåŠŸ - logits: {logits.shape}, values: {values.shape}")
    
    def test_feature_extraction_robustness(self):
        """æµ‹è¯•ç‰¹å¾æå–çš„é²æ£’æ€§"""
        print("\n=== æµ‹è¯•ç‰¹å¾æå–é²æ£’æ€§ ===")
        
        # æµ‹è¯•ä¸åŒè¾“å…¥ç»´åº¦
        test_dims = [64, 128, 256, 512]
        
        for dim in test_dims:
            print(f"\næµ‹è¯•è¾“å…¥ç»´åº¦: {dim}")
            
            # æ›´æ–°é…ç½®
            config = self.test_config.copy()
            config['total_input_dim'] = dim
            
            # åˆ›å»ºç‰¹å¾æå–å™¨
            extractor = RobustFeatureExtractor(config)
            
            # åˆ›å»ºæµ‹è¯•è¾“å…¥
            test_input = torch.randn(self.batch_size, dim)
            
            # æå–ç‰¹å¾
            try:
                uav_features, target_features, additional_features = extractor.extract_features(test_input)
                print(f"  âœ“ ç»´åº¦ {dim} æµ‹è¯•é€šè¿‡ - UAV: {uav_features.shape}, ç›®æ ‡: {target_features.shape}")
            except Exception as e:
                print(f"  âœ— ç»´åº¦ {dim} æµ‹è¯•å¤±è´¥: {e}")
                raise
    
    def test_attention_mechanism_effectiveness(self):
        """æµ‹è¯•æ³¨æ„åŠ›æœºåˆ¶çš„æœ‰æ•ˆæ€§"""
        print("\n=== æµ‹è¯•æ³¨æ„åŠ›æœºåˆ¶æœ‰æ•ˆæ€§ ===")
        
        from networks_fixed import GraphAttentionLayer
        
        # åˆ›å»ºä¸¤ä¸ªç›¸åŒçš„æ³¨æ„åŠ›å±‚
        attention_layer1 = GraphAttentionLayer(embed_dim=128, num_heads=8, dropout=0.0)
        attention_layer2 = GraphAttentionLayer(embed_dim=128, num_heads=8, dropout=0.0)
        
        # å¤åˆ¶æƒé‡ä»¥ç¡®ä¿åˆå§‹çŠ¶æ€ç›¸åŒ
        attention_layer2.load_state_dict(attention_layer1.state_dict())
        
        # åˆ›å»ºä¸¤ä¸ªä¸åŒçš„è¾“å…¥
        input1 = torch.randn(self.batch_size, 5, 128)
        input2 = torch.randn(self.batch_size, 5, 128)
        
        # å‰å‘ä¼ æ’­
        output1 = attention_layer1(input1)
        output2 = attention_layer2(input2)
        
        # éªŒè¯ä¸åŒè¾“å…¥äº§ç”Ÿä¸åŒè¾“å‡º
        self.assertFalse(torch.allclose(output1, output2, atol=1e-4))
        
        # éªŒè¯ç›¸åŒè¾“å…¥äº§ç”Ÿç›¸åŒè¾“å‡º
        output1_repeat = attention_layer1(input1)
        self.assertTrue(torch.allclose(output1, output1_repeat, atol=1e-6))
        
        print("âœ“ æ³¨æ„åŠ›æœºåˆ¶å¯¹ä¸åŒè¾“å…¥äº§ç”Ÿä¸åŒè¾“å‡º")
        print("âœ“ æ³¨æ„åŠ›æœºåˆ¶å¯¹ç›¸åŒè¾“å…¥äº§ç”Ÿç›¸åŒè¾“å‡º")
    
    def test_position_encoding_effectiveness(self):
        """æµ‹è¯•ä½ç½®ç¼–ç çš„æœ‰æ•ˆæ€§"""
        print("\n=== æµ‹è¯•ä½ç½®ç¼–ç æœ‰æ•ˆæ€§ ===")
        
        # åˆ›å»ºä½ç½®ç¼–ç å™¨
        position_encoder = RelativePositionEncoder(
            position_dim=2,
            embed_dim=64,
            max_distance=1000.0
        )
        
        # åˆ›å»ºä¸¤ç»„ä¸åŒçš„ç›¸å¯¹ä½ç½®
        pos1 = torch.tensor([[[100.0, 0.0], [0.0, 100.0]]], dtype=torch.float32)  # è¿‘è·ç¦»
        pos2 = torch.tensor([[[500.0, 0.0], [0.0, 500.0]]], dtype=torch.float32)  # è¿œè·ç¦»
        
        # ç”Ÿæˆä½ç½®ç¼–ç 
        emb1 = position_encoder(pos1)
        emb2 = position_encoder(pos2)
        
        # éªŒè¯ä¸åŒä½ç½®äº§ç”Ÿä¸åŒç¼–ç 
        self.assertFalse(torch.allclose(emb1, emb2, atol=1e-4))
        
        # éªŒè¯ç¼–ç çš„ä¸€è‡´æ€§
        emb1_repeat = position_encoder(pos1)
        self.assertTrue(torch.allclose(emb1, emb1_repeat, atol=1e-6))
        
        print("âœ“ ä¸åŒç›¸å¯¹ä½ç½®äº§ç”Ÿä¸åŒç¼–ç ")
        print("âœ“ ç›¸åŒç›¸å¯¹ä½ç½®äº§ç”Ÿç›¸åŒç¼–ç ")
        print(f"âœ“ è¿‘è·ç¦»ç¼–ç èŒƒå›´: [{emb1.min().item():.3f}, {emb1.max().item():.3f}]")
        print(f"âœ“ è¿œè·ç¦»ç¼–ç èŒƒå›´: [{emb2.min().item():.3f}, {emb2.max().item():.3f}]")
    
    def test_gradient_flow(self):
        """æµ‹è¯•æ¢¯åº¦æµåŠ¨"""
        print("\n=== æµ‹è¯•æ¢¯åº¦æµåŠ¨ ===")
        
        # åˆ›å»ºç½‘ç»œ
        network = TrueGraphAttentionNetwork(
            input_dim=self.input_dim,
            hidden_dims=self.hidden_dims,
            output_dim=self.output_dim,
            config=self.test_config
        )
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥å’Œç›®æ ‡
        test_input = torch.randn(self.batch_size, self.input_dim, requires_grad=True)
        target = torch.randn(self.batch_size, self.output_dim)
        
        # å‰å‘ä¼ æ’­
        output = network(test_input)
        
        # è®¡ç®—æŸå¤±
        loss = nn.MSELoss()(output, target)
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        # æ£€æŸ¥æ¢¯åº¦
        input_grad_norm = test_input.grad.norm().item()
        param_grads = [p.grad.norm().item() for p in network.parameters() if p.grad is not None]
        
        # éªŒè¯æ¢¯åº¦å­˜åœ¨ä¸”éé›¶
        self.assertGreater(input_grad_norm, 0)
        self.assertGreater(len(param_grads), 0)
        self.assertTrue(all(grad > 0 for grad in param_grads))
        
        print(f"âœ“ è¾“å…¥æ¢¯åº¦èŒƒæ•°: {input_grad_norm:.6f}")
        print(f"âœ“ å‚æ•°æ¢¯åº¦æ•°é‡: {len(param_grads)}")
        print(f"âœ“ å‚æ•°æ¢¯åº¦èŒƒæ•°èŒƒå›´: [{min(param_grads):.6f}, {max(param_grads):.6f}]")
    
    def test_comparison_with_original(self):
        """å¯¹æ¯”åŸå§‹å®ç°å’Œä¿®å¤ç‰ˆå®ç°"""
        print("\n=== å¯¹æ¯”åŸå§‹å®ç°å’Œä¿®å¤ç‰ˆå®ç° ===")
        
        # å¯¼å…¥åŸå§‹ç½‘ç»œï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            from networks import GATNetwork
            
            # åˆ›å»ºåŸå§‹ç½‘ç»œ
            original_network = GATNetwork(
                input_dim=self.input_dim,
                hidden_dims=self.hidden_dims,
                output_dim=self.output_dim,
                dropout=0.1
            )
            
            # åˆ›å»ºä¿®å¤ç‰ˆç½‘ç»œ
            fixed_network = TrueGraphAttentionNetwork(
                input_dim=self.input_dim,
                hidden_dims=self.hidden_dims,
                output_dim=self.output_dim,
                config=self.test_config
            )
            
            # åˆ›å»ºæµ‹è¯•è¾“å…¥
            test_input = torch.randn(self.batch_size, self.input_dim)
            
            # å‰å‘ä¼ æ’­
            original_output = original_network(test_input)
            fixed_output = fixed_network(test_input)
            
            # éªŒè¯è¾“å‡ºå½¢çŠ¶ç›¸åŒ
            self.assertEqual(original_output.shape, fixed_output.shape)
            
            # éªŒè¯è¾“å‡ºä¸å®Œå…¨ç›¸åŒï¼ˆè¯´æ˜å®ç°ç¡®å®ä¸åŒï¼‰
            self.assertFalse(torch.allclose(original_output, fixed_output, atol=1e-4))
            
            # ç»Ÿè®¡å‚æ•°æ•°é‡
            original_params = sum(p.numel() for p in original_network.parameters())
            fixed_params = sum(p.numel() for p in fixed_network.parameters())
            
            print(f"âœ“ åŸå§‹ç½‘ç»œå‚æ•°æ•°é‡: {original_params:,}")
            print(f"âœ“ ä¿®å¤ç‰ˆç½‘ç»œå‚æ•°æ•°é‡: {fixed_params:,}")
            print(f"âœ“ å‚æ•°æ•°é‡æ¯”ä¾‹: {fixed_params/original_params:.2f}")
            print("âœ“ è¾“å‡ºå½¢çŠ¶ä¸€è‡´ï¼Œä½†æ•°å€¼ä¸åŒï¼ˆç¡®è®¤å®ç°å·®å¼‚ï¼‰")
            
        except ImportError:
            print("âš  æ— æ³•å¯¼å…¥åŸå§‹ç½‘ç»œï¼Œè·³è¿‡å¯¹æ¯”æµ‹è¯•")


def run_comprehensive_tests():
    """è¿è¡Œå…¨é¢çš„æµ‹è¯•"""
    print("=" * 80)
    print("ä¿®å¤ç‰ˆç½‘ç»œå…¨é¢æµ‹è¯•")
    print("=" * 80)
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestFixedNetworks)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # è¾“å‡ºæ€»ç»“
    print("\n" + "=" * 80)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    
    if result.wasSuccessful():
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä¿®å¤ç‰ˆç½‘ç»œå®ç°æ­£ç¡®ã€‚")
        print("\nä¿®å¤æ•ˆæœæ€»ç»“ï¼š")
        print("âœ… é£é™©ç‚¹1ï¼šé²æ£’çš„ç‰¹å¾æå– - æ”¯æŒè¯­ä¹‰ã€æ¯”ä¾‹ã€å›ºå®šç»´åº¦ä¸‰ç§ç­–ç•¥")
        print("âœ… é£é™©ç‚¹2ï¼šçœŸæ­£çš„å›¾æ³¨æ„åŠ›æœºåˆ¶ - å®ç°å®Œæ•´çš„å¤šå¤´æ³¨æ„åŠ›è®¡ç®—")
        print("âœ… é£é™©ç‚¹3ï¼šå®Œæ•´çš„ç©ºé—´ä¿¡æ¯å¤„ç† - ç›¸å¯¹ä½ç½®ç¼–ç å’Œç»“æ„æ„ŸçŸ¥")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°ã€‚")
        print(f"å¤±è´¥æ•°é‡: {len(result.failures)}")
        print(f"é”™è¯¯æ•°é‡: {len(result.errors)}")
    
    return result.wasSuccessful()


if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡ç°æ€§
    torch.manual_seed(42)
    np.random.seed(42)
    
    # è¿è¡Œæµ‹è¯•
    success = run_comprehensive_tests()
    
    # é€€å‡ºç 
    exit(0 if success else 1)
