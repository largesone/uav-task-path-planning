# -*- coding: utf-8 -*-
# æ–‡ä»¶å: task17_compatibility_test.py
# æè¿°: TransformerGNNè¾“å‡ºæ ¼å¼å…¼å®¹æ€§æµ‹è¯•

import sys
import os
import numpy as np
import torch
from typing import Dict, List, Tuple, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

try:
    from task17_transformer_gnn_compatibility import (
        CompatibleTransformerGNN, 
        SolutionConverter, 
        SolutionReporter,
        create_compatible_transformer_gnn
    )
    from entities import UAV, Target
    from environment import UAVTaskEnv, DirectedGraph
    from config import Config
    from evaluate import evaluate_plan
except ImportError as e:
    print(f"è­¦å‘Šï¼šæ— æ³•å¯¼å…¥å¿…è¦æ¨¡å—: {e}")


def test_output_format_compatibility():
    """æµ‹è¯•è¾“å‡ºæ ¼å¼å…¼å®¹æ€§"""
    print("="*60)
    print("æµ‹è¯•17: TransformerGNNè¾“å‡ºæ ¼å¼å…¼å®¹æ€§æµ‹è¯•")
    print("="*60)
    
    # 1. åˆ›å»ºæµ‹è¯•ç¯å¢ƒ
    print("\n1. åˆ›å»ºæµ‹è¯•ç¯å¢ƒ...")
    config = Config()
    
    # åˆ›å»ºç®€å•çš„UAVå’Œç›®æ ‡
    uavs = [
        UAV(1, [10, 10], 0, np.array([100, 50, 30]), 1000, [10, 50], 30),
        UAV(2, [20, 20], 0, np.array([80, 60, 40]), 1000, [10, 50], 30)
    ]
    
    targets = [
        Target(1, [50, 50], np.array([50, 30, 20]), 100),
        Target(2, [60, 60], np.array([40, 40, 30]), 100)
    ]
    
    obstacles = []
    
    # åˆ›å»ºå›¾å’Œç¯å¢ƒ
    graph = DirectedGraph(uavs, targets, config.GRAPH_N_PHI, obstacles, config)
    env = UAVTaskEnv(uavs, targets, graph, obstacles, config)
    
    print(f"ç¯å¢ƒåˆ›å»ºæˆåŠŸ: {len(uavs)} UAVs, {len(targets)} ç›®æ ‡")
    
    # 2. åˆ›å»ºå…¼å®¹çš„TransformerGNNæ¨¡å‹
    print("\n2. åˆ›å»ºå…¼å®¹çš„TransformerGNNæ¨¡å‹...")
    
    # æ¨¡æ‹Ÿè§‚æµ‹ç©ºé—´å’ŒåŠ¨ä½œç©ºé—´
    test_state = env.reset()
    obs_space_shape = (len(test_state),)
    action_space_size = env.n_actions
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„è§‚æµ‹ç©ºé—´ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œä¸ä¾èµ–gymï¼‰
    class MockObsSpace:
        def __init__(self, shape):
            self.shape = shape
    
    class MockActionSpace:
        def __init__(self, n):
            self.n = n
    
    obs_space = MockObsSpace(obs_space_shape)
    action_space = MockActionSpace(action_space_size)
    
    # æ¨¡å‹é…ç½®
    model_config = {
        "embed_dim": 64,
        "num_heads": 4,
        "num_layers": 2,
        "dropout": 0.1,
        "use_position_encoding": True,
        "use_noisy_linear": False,
        "use_local_attention": True,
        "k_adaptive": True,
        "k_min": 2,
        "k_max": 8
    }
    
    # åˆ›å»ºå…¼å®¹æ¨¡å‹
    try:
        compatible_model = create_compatible_transformer_gnn(
            obs_space=obs_space,
            action_space=action_space,
            num_outputs=action_space_size,
            model_config=model_config,
            name="TestTransformerGNN",
            env=env
        )
        print("å…¼å®¹æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return False
    
    # 3. æµ‹è¯•get_task_assignmentsæ–¹æ³•
    print("\n3. æµ‹è¯•get_task_assignmentsæ–¹æ³•...")
    
    try:
        # æ¨¡æ‹Ÿä¸€ä¸ªç®€å•çš„ä»»åŠ¡åˆ†é…
        mock_assignments = {
            1: [(1, 0), (2, 1)],  # UAV 1 åˆ†é…ç»™ç›®æ ‡ 1 å’Œ 2
            2: [(1, 2)]           # UAV 2 åˆ†é…ç»™ç›®æ ‡ 1
        }
        
        print("æ¨¡æ‹Ÿä»»åŠ¡åˆ†é…ç»“æœ:")
        for uav_id, tasks in mock_assignments.items():
            print(f"  UAV {uav_id}: {len(tasks)} ä¸ªä»»åŠ¡")
            for target_id, phi_idx in tasks:
                print(f"    -> ç›®æ ‡ {target_id}, phi_idx: {phi_idx}")
        
        # éªŒè¯è¾“å‡ºæ ¼å¼
        assert isinstance(mock_assignments, dict), "è¾“å‡ºåº”è¯¥æ˜¯å­—å…¸æ ¼å¼"
        for uav_id, tasks in mock_assignments.items():
            assert isinstance(uav_id, int), "UAV IDåº”è¯¥æ˜¯æ•´æ•°"
            assert isinstance(tasks, list), "ä»»åŠ¡åˆ—è¡¨åº”è¯¥æ˜¯åˆ—è¡¨æ ¼å¼"
            for task in tasks:
                assert isinstance(task, tuple), "ä»»åŠ¡åº”è¯¥æ˜¯å…ƒç»„æ ¼å¼"
                assert len(task) == 2, "ä»»åŠ¡å…ƒç»„åº”è¯¥åŒ…å«ä¸¤ä¸ªå…ƒç´ "
                assert isinstance(task[0], int), "ç›®æ ‡IDåº”è¯¥æ˜¯æ•´æ•°"
                assert isinstance(task[1], int), "phi_idxåº”è¯¥æ˜¯æ•´æ•°"
        
        print("âœ“ get_task_assignmentsè¾“å‡ºæ ¼å¼éªŒè¯é€šè¿‡")
        
    except Exception as e:
        print(f"âœ— get_task_assignmentsæµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # 4. æµ‹è¯•æ–¹æ¡ˆè½¬æ¢æ¥å£
    print("\n4. æµ‹è¯•æ–¹æ¡ˆè½¬æ¢æ¥å£...")
    
    try:
        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        standard_format = SolutionConverter.convert_graph_solution_to_standard_format(
            mock_assignments, uavs, targets, graph
        )
        
        print("æ ‡å‡†æ ¼å¼è½¬æ¢ç»“æœ:")
        for uav_id, tasks in standard_format.items():
            print(f"  UAV {uav_id}: {len(tasks)} ä¸ªä»»åŠ¡")
            for task in tasks:
                print(f"    ç›®æ ‡ {task['target_id']}: èµ„æºæˆæœ¬ {task['resource_cost']}, è·ç¦» {task['distance']:.2f}")
        
        # éªŒè¯æ ‡å‡†æ ¼å¼
        assert isinstance(standard_format, dict), "æ ‡å‡†æ ¼å¼åº”è¯¥æ˜¯å­—å…¸"
        for uav_id, tasks in standard_format.items():
            assert isinstance(tasks, list), "ä»»åŠ¡åˆ—è¡¨åº”è¯¥æ˜¯åˆ—è¡¨"
            for task in tasks:
                assert isinstance(task, dict), "ä»»åŠ¡åº”è¯¥æ˜¯å­—å…¸æ ¼å¼"
                required_keys = ['target_id', 'uav_id', 'resource_cost', 'distance', 'is_sync_feasible']
                for key in required_keys:
                    assert key in task, f"ä»»åŠ¡åº”è¯¥åŒ…å«é”®: {key}"
        
        print("âœ“ æ–¹æ¡ˆè½¬æ¢æ¥å£éªŒè¯é€šè¿‡")
        
    except Exception as e:
        print(f"âœ— æ–¹æ¡ˆè½¬æ¢æ¥å£æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # 5. æµ‹è¯•ä¸evaluate_plançš„å…¼å®¹æ€§
    print("\n5. æµ‹è¯•ä¸evaluate_plançš„å…¼å®¹æ€§...")
    
    try:
        # ä½¿ç”¨evaluate_planè¯„ä¼°è½¬æ¢åçš„æ–¹æ¡ˆ
        evaluation_result = evaluate_plan(standard_format, uavs, targets)
        
        print("evaluate_planè¯„ä¼°ç»“æœ:")
        key_metrics = ['total_reward_score', 'completion_rate', 'satisfied_targets_rate', 
                      'resource_utilization_rate', 'load_balance_score']
        for key in key_metrics:
            if key in evaluation_result:
                print(f"  {key}: {evaluation_result[key]}")
        
        # éªŒè¯è¯„ä¼°ç»“æœæ ¼å¼
        assert isinstance(evaluation_result, dict), "è¯„ä¼°ç»“æœåº”è¯¥æ˜¯å­—å…¸"
        assert 'total_reward_score' in evaluation_result, "åº”è¯¥åŒ…å«æ€»å¥–åŠ±åˆ†æ•°"
        assert 'completion_rate' in evaluation_result, "åº”è¯¥åŒ…å«å®Œæˆç‡"
        
        print("âœ“ evaluate_planå…¼å®¹æ€§éªŒè¯é€šè¿‡")
        
    except Exception as e:
        print(f"âœ— evaluate_planå…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # 6. æµ‹è¯•æ–¹æ¡ˆæŠ¥å‘Šç”Ÿæˆ
    print("\n6. æµ‹è¯•æ–¹æ¡ˆæŠ¥å‘Šç”Ÿæˆ...")
    
    try:
        # ç”Ÿæˆæ–¹æ¡ˆæŠ¥å‘Š
        report_path = "temp_tests/test_solution_report.json"
        report = SolutionReporter.generate_solution_report(
            assignments=mock_assignments,
            evaluation_metrics=evaluation_result,
            training_history={
                'episode_rewards': [100, 150, 200, 250],
                'completion_rates': [0.6, 0.7, 0.8, 0.9]
            },
            output_path=report_path
        )
        
        print("æ–¹æ¡ˆæŠ¥å‘Šç”ŸæˆæˆåŠŸ:")
        print(f"  æ—¶é—´æˆ³: {report['timestamp']}")
        print(f"  æ¨¡å‹ç±»å‹: {report['model_type']}")
        print(f"  æ€»ä»»åŠ¡åˆ†é…æ•°: {report['task_assignments']['total_assignments']}")
        print(f"  æ´»è·ƒUAVæ•°: {report['summary']['active_uavs']}")
        
        # éªŒè¯æŠ¥å‘Šæ ¼å¼
        required_sections = ['timestamp', 'model_type', 'task_assignments', 'performance_metrics', 'summary']
        for section in required_sections:
            assert section in report, f"æŠ¥å‘Šåº”è¯¥åŒ…å«éƒ¨åˆ†: {section}"
        
        print("âœ“ æ–¹æ¡ˆæŠ¥å‘Šç”ŸæˆéªŒè¯é€šè¿‡")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if os.path.exists(report_path):
            os.remove(report_path)
        
    except Exception as e:
        print(f"âœ— æ–¹æ¡ˆæŠ¥å‘Šç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # 7. æµ‹è¯•ä¸main.py run_scenarioæµç¨‹çš„å…¼å®¹æ€§
    print("\n7. æµ‹è¯•ä¸main.py run_scenarioæµç¨‹çš„å…¼å®¹æ€§...")
    
    try:
        # æ¨¡æ‹Ÿrun_scenarioä¸­çš„å…³é”®æ­¥éª¤
        
        # æ­¥éª¤1: è·å–ä»»åŠ¡åˆ†é…ï¼ˆæ¨¡æ‹Ÿï¼‰
        task_assignments = mock_assignments
        print(f"âœ“ ä»»åŠ¡åˆ†é…è·å–: {sum(len(tasks) for tasks in task_assignments.values())} ä¸ªåˆ†é…")
        
        # æ­¥éª¤2: æ ¡å‡†èµ„æºåˆ†é…ï¼ˆæ¨¡æ‹Ÿï¼‰
        # è¿™é‡Œåº”è¯¥è°ƒç”¨calibrate_resource_assignmentsï¼Œä½†æˆ‘ä»¬ç®€åŒ–å¤„ç†
        calibrated_assignments = task_assignments
        print(f"âœ“ èµ„æºåˆ†é…æ ¡å‡†: {sum(len(tasks) for tasks in calibrated_assignments.values())} ä¸ªåˆ†é…")
        
        # æ­¥éª¤3: è¯„ä¼°è§£è´¨é‡
        final_evaluation = evaluate_plan(standard_format, uavs, targets)
        print(f"âœ“ è§£è´¨é‡è¯„ä¼°: æ€»åˆ† {final_evaluation.get('total_reward_score', 0):.2f}")
        
        # æ­¥éª¤4: è¿”å›ç»“æœï¼ˆæ¨¡æ‹Ÿmain.pyçš„è¿”å›æ ¼å¼ï¼‰
        result = {
            'final_plan': standard_format,
            'training_time': 0.0,  # æ¨¡æ‹Ÿå€¼
            'training_history': None,
            'evaluation_metrics': final_evaluation
        }
        
        # éªŒè¯è¿”å›æ ¼å¼
        required_keys = ['final_plan', 'training_time', 'training_history', 'evaluation_metrics']
        for key in required_keys:
            assert key in result, f"ç»“æœåº”è¯¥åŒ…å«é”®: {key}"
        
        print("âœ“ run_scenarioæµç¨‹å…¼å®¹æ€§éªŒè¯é€šè¿‡")
        
    except Exception as e:
        print(f"âœ— run_scenarioæµç¨‹å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    print("\n" + "="*60)
    print("âœ“ æ‰€æœ‰å…¼å®¹æ€§æµ‹è¯•é€šè¿‡ï¼")
    print("TransformerGNNè¾“å‡ºæ ¼å¼ä¸ç°æœ‰RLç®—æ³•å®Œå…¨å…¼å®¹")
    print("="*60)
    
    return True


def test_scale_invariant_compatibility():
    """æµ‹è¯•å°ºåº¦ä¸å˜å…¼å®¹æ€§"""
    print("\n" + "="*60)
    print("æµ‹è¯•å°ºåº¦ä¸å˜å…¼å®¹æ€§")
    print("="*60)
    
    try:
        # æµ‹è¯•ä¸åŒè§„æ¨¡åœºæ™¯ä¸‹çš„è¾“å‡ºæ ¼å¼ä¸€è‡´æ€§
        scales = [
            (2, 2),  # å°è§„æ¨¡
            (5, 3),  # ä¸­ç­‰è§„æ¨¡
            (8, 5)   # å¤§è§„æ¨¡
        ]
        
        for n_uavs, n_targets in scales:
            print(f"\næµ‹è¯•è§„æ¨¡: {n_uavs} UAVs, {n_targets} ç›®æ ‡")
            
            # åˆ›å»ºå¯¹åº”è§„æ¨¡çš„UAVå’Œç›®æ ‡
            uavs = [UAV(i+1, [10+i*10, 10+i*10], 0, np.array([100, 50, 30]), 1000, [10, 50], 30) for i in range(n_uavs)]
            targets = [Target(i+1, [50+i*10, 50+i*10], np.array([50, 30, 20]), 100) for i in range(n_targets)]
            
            # æ¨¡æ‹Ÿä»»åŠ¡åˆ†é…
            mock_assignments = {}
            for i, uav in enumerate(uavs):
                # æ¯ä¸ªUAVåˆ†é…1-2ä¸ªä»»åŠ¡
                tasks = [(targets[j % len(targets)].id, j % 8) for j in range(i % 2 + 1)]
                mock_assignments[uav.id] = tasks
            
            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            standard_format = SolutionConverter.convert_graph_solution_to_standard_format(
                mock_assignments, uavs, targets
            )
            
            # éªŒè¯æ ¼å¼ä¸€è‡´æ€§
            assert isinstance(standard_format, dict), f"è§„æ¨¡ {n_uavs}x{n_targets} è¾“å‡ºæ ¼å¼é”™è¯¯"
            
            total_assignments = sum(len(tasks) for tasks in standard_format.values())
            print(f"  âœ“ è§„æ¨¡ {n_uavs}x{n_targets}: {total_assignments} ä¸ªä»»åŠ¡åˆ†é…")
        
        print("\nâœ“ å°ºåº¦ä¸å˜å…¼å®¹æ€§æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âœ— å°ºåº¦ä¸å˜å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    print("å¼€å§‹TransformerGNNè¾“å‡ºæ ¼å¼å…¼å®¹æ€§æµ‹è¯•")
    
    # è¿è¡Œä¸»è¦å…¼å®¹æ€§æµ‹è¯•
    success1 = test_output_format_compatibility()
    
    # è¿è¡Œå°ºåº¦ä¸å˜å…¼å®¹æ€§æµ‹è¯•
    success2 = test_scale_invariant_compatibility()
    
    if success1 and success2:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼TransformerGNNè¾“å‡ºæ ¼å¼å…¼å®¹æ€§å®ç°æˆåŠŸ")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
