# -*- coding: utf-8 -*-
# æ–‡ä»¶å: test_risk_fixes_validation.py
# æè¿°: ä¸“é—¨éªŒè¯ä¸‰ä¸ªé£é™©ç‚¹ä¿®å¤æ•ˆæœçš„è¯¦ç»†æµ‹è¯•

import torch
import torch.nn as nn
import numpy as np
import sys
import os
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from networks import GATNetwork  # åŸå§‹å®ç°
from networks_fixed import TrueGraphAttentionNetwork, RobustFeatureExtractor  # ä¿®å¤ç‰ˆå®ç°
from transformer_gnn_fixed import FixedTransformerGNN
from gymnasium import spaces

def test_risk_point_1_feature_extraction():
    """è¯¦ç»†æµ‹è¯•é£é™©ç‚¹1ï¼šç‰¹å¾æå–çš„é²æ£’æ€§"""
    print("=" * 80)
    print("é£é™©ç‚¹1ä¿®å¤éªŒè¯ï¼šé²æ£’çš„ç‰¹å¾æå–")
    print("=" * 80)
    
    # æµ‹è¯•ä¸åŒçš„çŠ¶æ€ç»´åº¦å˜åŒ–
    test_scenarios = [
        {"input_dim": 64, "description": "å°è§„æ¨¡åœºæ™¯"},
        {"input_dim": 128, "description": "æ ‡å‡†åœºæ™¯"},
        {"input_dim": 256, "description": "å¤§è§„æ¨¡åœºæ™¯"},
        {"input_dim": 512, "description": "è¶…å¤§è§„æ¨¡åœºæ™¯"},
    ]
    
    for scenario in test_scenarios:
        print(f"\næµ‹è¯•åœºæ™¯: {scenario['description']} (ç»´åº¦: {scenario['input_dim']})")
        
        # åŸå§‹å®ç°ï¼ˆè„†å¼±çš„å¯¹åŠåˆ‡åˆ†ï¼‰
        try:
            original_network = GATNetwork(
                input_dim=scenario['input_dim'],
                hidden_dims=[128, 64],
                output_dim=10,
                dropout=0.1
            )
            test_input = torch.randn(4, scenario['input_dim'])
            original_output = original_network(test_input)
            print(f"  âœ“ åŸå§‹å®ç°æˆåŠŸ - è¾“å‡ºå½¢çŠ¶: {original_output.shape}")
        except Exception as e:
            print(f"  âœ— åŸå§‹å®ç°å¤±è´¥: {e}")
        
        # ä¿®å¤ç‰ˆå®ç°ï¼ˆé²æ£’çš„ç‰¹å¾æå–ï¼‰
        try:
            config = {
                'extraction_strategy': 'semantic',
                'total_input_dim': scenario['input_dim'],
                'embedding_dim': 128,
                'num_heads': 8,
                'dropout': 0.1,
                'n_uavs': 2,
                'n_targets': 3,
                'uav_features_per_entity': 8,
                'target_features_per_entity': 7,
                'max_distance': 1000.0
            }
            
            fixed_network = TrueGraphAttentionNetwork(
                input_dim=scenario['input_dim'],
                hidden_dims=[128, 64],
                output_dim=10,
                config=config
            )
            test_input = torch.randn(4, scenario['input_dim'])
            fixed_output = fixed_network(test_input)
            print(f"  âœ“ ä¿®å¤ç‰ˆå®ç°æˆåŠŸ - è¾“å‡ºå½¢çŠ¶: {fixed_output.shape}")
            
            # æµ‹è¯•ç‰¹å¾æå–çš„ä¸€è‡´æ€§
            extractor = RobustFeatureExtractor(config)
            uav_features, target_features, additional = extractor.extract_features(test_input)
            print(f"    - UAVç‰¹å¾: {uav_features.shape}, ç›®æ ‡ç‰¹å¾: {target_features.shape}")
            print(f"    - é¢å¤–ç‰¹å¾: {list(additional.keys())}")
            
        except Exception as e:
            print(f"  âœ— ä¿®å¤ç‰ˆå®ç°å¤±è´¥: {e}")

def test_risk_point_2_attention_mechanism():
    """è¯¦ç»†æµ‹è¯•é£é™©ç‚¹2ï¼šçœŸæ­£çš„æ³¨æ„åŠ›æœºåˆ¶"""
    print("\n" + "=" * 80)
    print("é£é™©ç‚¹2ä¿®å¤éªŒè¯ï¼šçœŸæ­£çš„å›¾æ³¨æ„åŠ›æœºåˆ¶")
    print("=" * 80)
    
    batch_size = 4
    input_dim = 128
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    test_input = torch.randn(batch_size, input_dim)
    
    # åŸå§‹å®ç°ï¼ˆä¼ªæ³¨æ„åŠ›ï¼‰
    print("\nåŸå§‹å®ç°åˆ†æ:")
    original_network = GATNetwork(input_dim, [128, 64], 10, dropout=0.1)
    
    # æ£€æŸ¥æ˜¯å¦çœŸçš„ä½¿ç”¨äº†æ³¨æ„åŠ›
    has_attention = hasattr(original_network, 'attention')
    print(f"  - å®šä¹‰äº†æ³¨æ„åŠ›æ¨¡å—: {has_attention}")
    
    if has_attention:
        # æ£€æŸ¥å‰å‘ä¼ æ’­ä¸­æ˜¯å¦ä½¿ç”¨äº†æ³¨æ„åŠ›
        original_output = original_network(test_input)
        print(f"  - è¾“å‡ºå½¢çŠ¶: {original_output.shape}")
        print("  - æ³¨æ„åŠ›æœºåˆ¶ä½¿ç”¨æƒ…å†µ: ä»…å®šä¹‰æœªä½¿ç”¨ï¼ˆä¼ªæ³¨æ„åŠ›ï¼‰")
    
    # ä¿®å¤ç‰ˆå®ç°ï¼ˆçœŸæ­£çš„æ³¨æ„åŠ›ï¼‰
    print("\nä¿®å¤ç‰ˆå®ç°åˆ†æ:")
    config = {
        'extraction_strategy': 'semantic',
        'total_input_dim': input_dim,
        'embedding_dim': 128,
        'num_heads': 8,
        'dropout': 0.1,
        'num_attention_layers': 2,
        'n_uavs': 2,
        'n_targets': 3,
        'uav_features_per_entity': 8,
        'target_features_per_entity': 7,
        'max_distance': 1000.0
    }
    
    fixed_network = TrueGraphAttentionNetwork(input_dim, [128, 64], 10, config)
    fixed_output = fixed_network(test_input)
    
    print(f"  - è¾“å‡ºå½¢çŠ¶: {fixed_output.shape}")
    print(f"  - å›¾æ³¨æ„åŠ›å±‚æ•°é‡: {len(fixed_network.graph_attention_layers)}")
    print("  - æ³¨æ„åŠ›æœºåˆ¶ä½¿ç”¨æƒ…å†µ: å®Œæ•´çš„å¤šå¤´å›¾æ³¨æ„åŠ›è®¡ç®—")
    
    # éªŒè¯æ³¨æ„åŠ›çš„æœ‰æ•ˆæ€§
    print("\næ³¨æ„åŠ›æœ‰æ•ˆæ€§éªŒè¯:")
    
    # åˆ›å»ºä¸¤ä¸ªä¸åŒçš„è¾“å…¥
    input1 = torch.randn(batch_size, input_dim)
    input2 = torch.randn(batch_size, input_dim)
    
    output1 = fixed_network(input1)
    output2 = fixed_network(input2)
    
    # éªŒè¯ä¸åŒè¾“å…¥äº§ç”Ÿä¸åŒè¾“å‡º
    attention_effective = not torch.allclose(output1, output2, atol=1e-4)
    print(f"  - ä¸åŒè¾“å…¥äº§ç”Ÿä¸åŒè¾“å‡º: {attention_effective}")
    
    # éªŒè¯ç›¸åŒè¾“å…¥äº§ç”Ÿç›¸åŒè¾“å‡º
    output1_repeat = fixed_network(input1)
    attention_consistent = torch.allclose(output1, output1_repeat, atol=1e-6)
    print(f"  - ç›¸åŒè¾“å…¥äº§ç”Ÿç›¸åŒè¾“å‡º: {attention_consistent}")

def test_risk_point_3_spatial_information():
    """è¯¦ç»†æµ‹è¯•é£é™©ç‚¹3ï¼šç©ºé—´ä¿¡æ¯å¤„ç†"""
    print("\n" + "=" * 80)
    print("é£é™©ç‚¹3ä¿®å¤éªŒè¯ï¼šå®Œæ•´çš„ç©ºé—´ä¿¡æ¯å¤„ç†")
    print("=" * 80)
    
    from networks_fixed import RelativePositionEncoder
    
    # æµ‹è¯•ä½ç½®ç¼–ç å™¨
    print("\nä½ç½®ç¼–ç å™¨æµ‹è¯•:")
    position_encoder = RelativePositionEncoder(
        position_dim=2,
        embed_dim=64,
        max_distance=1000.0,
        num_distance_bins=32,
        num_angle_bins=16
    )
    
    # åˆ›å»ºä¸åŒçš„ç©ºé—´é…ç½®
    spatial_scenarios = [
        {
            "name": "è¿‘è·ç¦»é…ç½®",
            "positions": torch.tensor([[[50.0, 0.0], [0.0, 50.0]]], dtype=torch.float32)
        },
        {
            "name": "ä¸­è·ç¦»é…ç½®", 
            "positions": torch.tensor([[[200.0, 100.0], [100.0, 200.0]]], dtype=torch.float32)
        },
        {
            "name": "è¿œè·ç¦»é…ç½®",
            "positions": torch.tensor([[[500.0, 300.0], [300.0, 500.0]]], dtype=torch.float32)
        }
    ]
    
    encodings = []
    for scenario in spatial_scenarios:
        encoding = position_encoder(scenario["positions"])
        encodings.append(encoding)
        
        print(f"  - {scenario['name']}: ç¼–ç å½¢çŠ¶ {encoding.shape}")
        print(f"    ç¼–ç èŒƒå›´: [{encoding.min().item():.3f}, {encoding.max().item():.3f}]")
    
    # éªŒè¯ä¸åŒç©ºé—´é…ç½®äº§ç”Ÿä¸åŒç¼–ç 
    print("\nç©ºé—´æ„ŸçŸ¥èƒ½åŠ›éªŒè¯:")
    for i in range(len(encodings)):
        for j in range(i+1, len(encodings)):
            different = not torch.allclose(encodings[i], encodings[j], atol=1e-3)
            print(f"  - {spatial_scenarios[i]['name']} vs {spatial_scenarios[j]['name']}: ç¼–ç ä¸åŒ = {different}")
    
    # æµ‹è¯•å®Œæ•´çš„TransformerGNNç©ºé—´å¤„ç†
    print("\nå®Œæ•´TransformerGNNç©ºé—´å¤„ç†æµ‹è¯•:")
    
    # åˆ›å»ºå­—å…¸è§‚æµ‹ç©ºé—´ï¼ˆåŒ…å«ç©ºé—´ä¿¡æ¯ï¼‰
    obs_space = spaces.Dict({
        'uav_features': spaces.Box(low=-np.inf, high=np.inf, shape=(2, 9), dtype=np.float32),
        'target_features': spaces.Box(low=-np.inf, high=np.inf, shape=(3, 8), dtype=np.float32),
        'relative_positions': spaces.Box(low=-1.0, high=1.0, shape=(2, 3, 2), dtype=np.float32),
        'distances': spaces.Box(low=0.0, high=1.0, shape=(2, 3), dtype=np.float32),
        'masks': spaces.Dict({
            'uav_mask': spaces.Box(low=0, high=1, shape=(2,), dtype=np.int32),
            'target_mask': spaces.Box(low=0, high=1, shape=(3,), dtype=np.int32)
        })
    })
    
    action_space = spaces.Discrete(10)
    
    model_config = {
        "embed_dim": 128,
        "num_heads": 8,
        "num_layers": 2,
        "dropout": 0.1,
        "use_position_encoding": True,
        "use_local_attention": True,
        "use_noisy_linear": False,
        "k_adaptive": True,
        "k_min": 2,
        "k_max": 3
    }
    
    model = FixedTransformerGNN(
        obs_space=obs_space,
        action_space=action_space,
        num_outputs=10,
        model_config=model_config,
        name="SpatialTestModel"
    )
    
    # åˆ›å»ºåŒ…å«ä¸åŒç©ºé—´é…ç½®çš„æµ‹è¯•è¾“å…¥
    spatial_test_cases = [
        {
            "name": "èšé›†é…ç½®",
            "relative_positions": torch.randn(4, 2, 3, 2) * 0.1,  # å°çš„ç›¸å¯¹ä½ç½®
            "distances": torch.rand(4, 2, 3) * 0.2  # å°è·ç¦»
        },
        {
            "name": "åˆ†æ•£é…ç½®", 
            "relative_positions": torch.randn(4, 2, 3, 2) * 0.8,  # å¤§çš„ç›¸å¯¹ä½ç½®
            "distances": torch.rand(4, 2, 3) * 0.8 + 0.2  # å¤§è·ç¦»
        }
    ]
    
    outputs = []
    for test_case in spatial_test_cases:
        input_dict = {
            "obs": {
                'uav_features': torch.randn(4, 2, 9),
                'target_features': torch.randn(4, 3, 8),
                'relative_positions': test_case["relative_positions"],
                'distances': test_case["distances"],
                'masks': {
                    'uav_mask': torch.ones(4, 2, dtype=torch.int32),
                    'target_mask': torch.ones(4, 3, dtype=torch.int32)
                }
            }
        }
        
        logits, _ = model.forward(input_dict, [], None)
        outputs.append(logits)
        print(f"  - {test_case['name']}: è¾“å‡ºå½¢çŠ¶ {logits.shape}")
    
    # éªŒè¯ä¸åŒç©ºé—´é…ç½®äº§ç”Ÿä¸åŒè¾“å‡º
    spatial_aware = not torch.allclose(outputs[0], outputs[1], atol=1e-3)
    print(f"  - ç©ºé—´æ„ŸçŸ¥èƒ½åŠ›: {spatial_aware}")

def performance_comparison():
    """æ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
    print("\n" + "=" * 80)
    print("æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print("=" * 80)
    
    batch_size = 8
    input_dim = 128
    num_iterations = 100
    
    # åŸå§‹å®ç°æ€§èƒ½æµ‹è¯•
    print("\nåŸå§‹å®ç°æ€§èƒ½:")
    original_network = GATNetwork(input_dim, [128, 64], 10, dropout=0.1)
    test_input = torch.randn(batch_size, input_dim)
    
    # é¢„çƒ­
    for _ in range(10):
        _ = original_network(test_input)
    
    start_time = time.time()
    for _ in range(num_iterations):
        output = original_network(test_input)
    original_time = time.time() - start_time
    
    original_params = sum(p.numel() for p in original_network.parameters())
    print(f"  - å‚æ•°æ•°é‡: {original_params:,}")
    print(f"  - å¹³å‡æ¨ç†æ—¶é—´: {original_time/num_iterations*1000:.2f} ms")
    
    # ä¿®å¤ç‰ˆå®ç°æ€§èƒ½æµ‹è¯•
    print("\nä¿®å¤ç‰ˆå®ç°æ€§èƒ½:")
    config = {
        'extraction_strategy': 'semantic',
        'total_input_dim': input_dim,
        'embedding_dim': 128,
        'num_heads': 8,
        'dropout': 0.1,
        'num_attention_layers': 2,
        'n_uavs': 2,
        'n_targets': 3,
        'uav_features_per_entity': 8,
        'target_features_per_entity': 7,
        'max_distance': 1000.0
    }
    
    fixed_network = TrueGraphAttentionNetwork(input_dim, [128, 64], 10, config)
    
    # é¢„çƒ­
    for _ in range(10):
        _ = fixed_network(test_input)
    
    start_time = time.time()
    for _ in range(num_iterations):
        output = fixed_network(test_input)
    fixed_time = time.time() - start_time
    
    fixed_params = sum(p.numel() for p in fixed_network.parameters())
    print(f"  - å‚æ•°æ•°é‡: {fixed_params:,}")
    print(f"  - å¹³å‡æ¨ç†æ—¶é—´: {fixed_time/num_iterations*1000:.2f} ms")
    
    # æ€§èƒ½å¯¹æ¯”
    print(f"\næ€§èƒ½å¯¹æ¯”:")
    print(f"  - å‚æ•°æ•°é‡æ¯”ä¾‹: {fixed_params/original_params:.2f}x")
    print(f"  - æ¨ç†æ—¶é—´æ¯”ä¾‹: {fixed_time/original_time:.2f}x")
    print(f"  - åŠŸèƒ½æå‡: é²æ£’ç‰¹å¾æå– + çœŸæ­£æ³¨æ„åŠ› + ç©ºé—´æ„ŸçŸ¥")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ä¿®å¤ç‰ˆç½‘ç»œé£é™©ç‚¹éªŒè¯æµ‹è¯•")
    print("æµ‹è¯•ç›®æ ‡ï¼šéªŒè¯ä¸‰ä¸ªå…³é”®é£é™©ç‚¹çš„ä¿®å¤æ•ˆæœ")
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    
    try:
        # æµ‹è¯•é£é™©ç‚¹1ï¼šç‰¹å¾æå–
        test_risk_point_1_feature_extraction()
        
        # æµ‹è¯•é£é™©ç‚¹2ï¼šæ³¨æ„åŠ›æœºåˆ¶
        test_risk_point_2_attention_mechanism()
        
        # æµ‹è¯•é£é™©ç‚¹3ï¼šç©ºé—´ä¿¡æ¯å¤„ç†
        test_risk_point_3_spatial_information()
        
        # æ€§èƒ½å¯¹æ¯”
        performance_comparison()
        
        print("\n" + "=" * 80)
        print("ğŸ‰ æ‰€æœ‰é£é™©ç‚¹ä¿®å¤éªŒè¯æµ‹è¯•é€šè¿‡ï¼")
        print("=" * 80)
        print("\nä¿®å¤æ€»ç»“:")
        print("âœ… é£é™©ç‚¹1ï¼šé²æ£’çš„ç‰¹å¾æå– - è§£å†³äº†ç®€åŒ–å¯¹åŠåˆ‡åˆ†çš„è„†å¼±æ€§")
        print("âœ… é£é™©ç‚¹2ï¼šçœŸæ­£çš„å›¾æ³¨æ„åŠ›æœºåˆ¶ - å®ç°äº†å®Œæ•´çš„å¤šå¤´æ³¨æ„åŠ›è®¡ç®—")
        print("âœ… é£é™©ç‚¹3ï¼šå®Œæ•´çš„ç©ºé—´ä¿¡æ¯å¤„ç† - æ·»åŠ äº†ç›¸å¯¹ä½ç½®ç¼–ç å’Œç»“æ„æ„ŸçŸ¥")
        print("\nç½‘ç»œç°åœ¨å…·å¤‡:")
        print("ğŸ”§ è¯­ä¹‰æ„ŸçŸ¥çš„ç‰¹å¾æå–")
        print("ğŸ§  çœŸæ­£çš„å›¾æ³¨æ„åŠ›è®¡ç®—")
        print("ğŸ“ å®Œæ•´çš„ç©ºé—´ä¿¡æ¯å¤„ç†")
        print("ğŸš€ é›¶æ ·æœ¬è¿ç§»èƒ½åŠ›")
        print("ğŸ›¡ï¸ é²æ£’æ€§å’Œå¯æ‰©å±•æ€§")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)