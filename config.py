# -*- coding: utf-8 -*-
# æ–‡ä»¶å: config.py
# æè¿°: ç»Ÿä¸€ç®¡ç†é¡¹ç›®çš„æ‰€æœ‰é…ç½®å‚æ•°ï¼ŒåŒ…æ‹¬è®­ç»ƒé…ç½®å’ŒPBRSé…ç½®
#
# PBRS (Potential-Based Reward Shaping) é…ç½®è¯´æ˜:
# ===============================================
# 
# æœ¬æ–‡ä»¶æ–°å¢äº†å®Œæ•´çš„PBRSé…ç½®ç®¡ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
# 
# 1. åŠ¿å‡½æ•°æƒé‡å‚æ•°:
#    - PBRS_COMPLETION_WEIGHT: å®Œæˆåº¦åŠ¿èƒ½æƒé‡ (é»˜è®¤: 10.0)
#    - PBRS_DISTANCE_WEIGHT: è·ç¦»åŠ¿èƒ½æƒé‡ (é»˜è®¤: 0.01)
#    - PBRS_COLLABORATION_WEIGHT: åä½œåŠ¿èƒ½æƒé‡ (é»˜è®¤: 5.0)
# 
# 2. æ•°å€¼ç¨³å®šæ€§å‚æ•°:
#    - PBRS_REWARD_CLIP_MIN/MAX: å¡‘å½¢å¥–åŠ±è£å‰ªèŒƒå›´ (é»˜è®¤: -50.0 ~ 50.0)
#    - PBRS_POTENTIAL_CLIP_MIN/MAX: åŠ¿å‡½æ•°å€¼è£å‰ªèŒƒå›´ (é»˜è®¤: -1000.0 ~ 1000.0)
#    - PBRS_MAX_POTENTIAL_CHANGE: å•æ­¥æœ€å¤§åŠ¿å‡½æ•°å˜åŒ–é‡ (é»˜è®¤: 100.0)
# 
# 3. è°ƒè¯•å’Œç›‘æ§å‚æ•°:
#    - PBRS_DEBUG_MODE: è°ƒè¯•æ¨¡å¼å¼€å…³ (é»˜è®¤: False)
#    - PBRS_LOG_POTENTIAL_VALUES: è®°å½•åŠ¿å‡½æ•°å€¼ (é»˜è®¤: False)
#    - PBRS_LOG_REWARD_BREAKDOWN: è®°å½•å¥–åŠ±ç»„æˆè¯¦æƒ… (é»˜è®¤: False)
# 
# 4. æ€§èƒ½ä¼˜åŒ–å‚æ•°:
#    - PBRS_ENABLE_DISTANCE_CACHE: å¯ç”¨è·ç¦»ç¼“å­˜ (é»˜è®¤: True)
#    - PBRS_CACHE_UPDATE_THRESHOLD: ç¼“å­˜æ›´æ–°é˜ˆå€¼ (é»˜è®¤: 0.1)
# 
# ä½¿ç”¨ç¤ºä¾‹:
# --------
# config = Config()
# config.update_pbrs_params(PBRS_DEBUG_MODE=True, PBRS_COMPLETION_WEIGHT=15.0)
# config.print_pbrs_config()
# config.save_pbrs_config("my_pbrs_config.pkl")
# 
# éªŒè¯å’Œå®‰å…¨æ€§:
# -----------
# - æ‰€æœ‰å‚æ•°éƒ½æœ‰è‡ªåŠ¨éªŒè¯æœºåˆ¶
# - æ— æ•ˆé…ç½®ä¼šè‡ªåŠ¨é‡ç½®ä¸ºé»˜è®¤å€¼
# - æä¾›é…ç½®ä¿å­˜/åŠ è½½åŠŸèƒ½
# - æ”¯æŒè¿è¡Œæ—¶å‚æ•°è°ƒæ•´

import os
import pickle
from typing import Optional, Dict, Any, List
from dataclasses import dataclass, field

@dataclass
class TrainingConfig:
    """è®­ç»ƒé…ç½®ç±» - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰è®­ç»ƒå‚æ•°"""
    
    # ===== åŸºç¡€è®­ç»ƒå‚æ•° =====
    episodes: int = 2000                   # è®­ç»ƒè½®æ¬¡
    learning_rate: float = 0.00005         # é™ä½å­¦ä¹ ç‡ï¼Œæé«˜æ•°å€¼ç¨³å®šæ€§
    gamma: float = 0.99                    # æé«˜æŠ˜æ‰£å› å­ï¼Œæ›´é‡è§†é•¿æœŸå¥–åŠ±
    batch_size: int = 64                   # å‡å°æ‰¹æ¬¡å¤§å°ï¼Œæé«˜æ›´æ–°é¢‘ç‡
    memory_size: int = 15000               # é€‚å½“å‡å°è®°å¿†åº“ï¼Œé¿å…è¿‡æ—§ç»éªŒ
    
    # ===== æ¢ç´¢ç­–ç•¥å‚æ•° =====
    epsilon_start: float = 0.9             # é™ä½åˆå§‹æ¢ç´¢ç‡
    epsilon_end: float = 0.1               # æé«˜æœ€ç»ˆæ¢ç´¢ç‡ï¼Œä¿æŒé€‚åº¦æ¢ç´¢
    epsilon_decay: float = 0.9995          # æ”¾ç¼“æ¢ç´¢ç‡è¡°å‡
    epsilon_min: float = 0.1               # æé«˜æœ€å°æ¢ç´¢ç‡
    
    # ===== ç½‘ç»œæ›´æ–°å‚æ•° =====
    target_update_freq: int = 20           # é™ä½ç›®æ ‡ç½‘ç»œæ›´æ–°é¢‘ç‡ï¼Œå¢åŠ ç¨³å®šæ€§
    patience: int = 100                    # å¢åŠ æ—©åœè€å¿ƒå€¼
    log_interval: int = 20                 # å‡å°‘æ—¥å¿—è¾“å‡ºé¢‘ç‡
    
    # ===== æ¢¯åº¦è£å‰ªå‚æ•° =====
    use_gradient_clipping: bool = True     # æ˜¯å¦ä½¿ç”¨æ¢¯åº¦è£å‰ª
    max_grad_norm: float = 1.0             # æœ€å¤§æ¢¯åº¦èŒƒæ•°
    
    # ===== ä¼˜å…ˆç»éªŒå›æ”¾å‚æ•° =====
    use_prioritized_replay: bool = True    # æ˜¯å¦ä½¿ç”¨ä¼˜å…ˆç»éªŒå›æ”¾
    per_alpha: float = 0.6                 # ä¼˜å…ˆçº§æŒ‡æ•° (0=å‡åŒ€é‡‡æ ·, 1=å®Œå…¨ä¼˜å…ˆçº§é‡‡æ ·)
    per_beta_start: float = 0.4            # é‡è¦æ€§é‡‡æ ·æƒé‡åˆå§‹å€¼
    per_beta_frames: int = 100000          # Î²ä»åˆå§‹å€¼å¢é•¿åˆ°1.0çš„å¸§æ•°
    per_epsilon: float = 1e-6              # é˜²æ­¢ä¼˜å…ˆçº§ä¸º0çš„å°å€¼
    
    # ===== è°ƒè¯•å‚æ•° =====
    verbose: bool = True                   # è¯¦ç»†è¾“å‡º
    debug_mode: bool = False               # è°ƒè¯•æ¨¡å¼
    save_training_history: bool = True     # ä¿å­˜è®­ç»ƒå†å²

class Config:
    """ç»Ÿä¸€ç®¡ç†æ‰€æœ‰ç®—æ³•å’Œæ¨¡æ‹Ÿçš„å‚æ•°"""
    
    def __init__(self):
        # ----- è®­ç»ƒç³»ç»Ÿæ§åˆ¶å‚æ•° -----
        # è®­ç»ƒæ¨¡å¼é€‰æ‹©ï¼š
        # - 'training': è®­ç»ƒæ¨¡å¼ï¼Œä»å¤´å¼€å§‹è®­ç»ƒæˆ–ç»§ç»­è®­ç»ƒ
        # - 'inference': æ¨ç†æ¨¡å¼ï¼Œä»…åŠ è½½å·²è®­ç»ƒæ¨¡å‹è¿›è¡Œæ¨ç†
        # - 'zero_shot_train': é›¶æ ·æœ¬è®­ç»ƒæ¨¡å¼ï¼Œä¸“ç”¨äºZeroShotGNN
        self.TRAINING_MODE = 'zero_shot_train'
        
        # å¼ºåˆ¶é‡æ–°è®­ç»ƒæ ‡å¿—ï¼š
        # - True: å¿½ç•¥å·²æœ‰æ¨¡å‹ï¼Œå¼ºåˆ¶é‡æ–°è®­ç»ƒ
        # - False: ä¼˜å…ˆåŠ è½½å·²æœ‰æ¨¡å‹ï¼Œä¸å­˜åœ¨æ—¶æ‰è®­ç»ƒ
        self.FORCE_RETRAIN = True
        
        # è·¯å¾„è§„åˆ’ç²¾åº¦æ§åˆ¶ï¼š
        # - True: ä½¿ç”¨é«˜ç²¾åº¦PH-RRTç®—æ³•ï¼Œè®¡ç®—å‡†ç¡®ä½†è€—æ—¶
        # - False: ä½¿ç”¨å¿«é€Ÿè¿‘ä¼¼ç®—æ³•ï¼Œè®¡ç®—å¿«é€Ÿä½†ç²¾åº¦è¾ƒä½
        self.USE_PHRRT_DURING_TRAINING = True          # è®­ç»ƒæ—¶æ˜¯å¦ä½¿ç”¨é«˜ç²¾åº¦PH-RRT
        self.USE_PHRRT_DURING_PLANNING = True          # è§„åˆ’æ—¶æ˜¯å¦ä½¿ç”¨é«˜ç²¾åº¦PH-RRT
        
        # æ¨¡å‹ä¿å­˜/åŠ è½½è·¯å¾„é…ç½®
        self.SAVED_MODEL_PATH = 'output/models/saved_model_final.pth'
        
        # ----- ç½‘ç»œç»“æ„é€‰æ‹©å‚æ•° -----
        # ç½‘ç»œç»“æ„ç±»å‹é€‰æ‹©ï¼Œæ”¯æŒä»¥ä¸‹å€™é€‰é¡¹ï¼š
        # - 'SimpleNetwork': åŸºç¡€å…¨è¿æ¥ç½‘ç»œï¼Œé€‚åˆç®€å•åœºæ™¯ï¼Œè®­ç»ƒå¿«é€Ÿ
        # - 'DeepFCN': æ·±åº¦å…¨è¿æ¥ç½‘ç»œï¼Œå…·æœ‰æ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›
        # - 'DeepFCNResidual': å¸¦æ®‹å·®è¿æ¥çš„æ·±åº¦ç½‘ç»œï¼Œç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜
        # - 'ZeroShotGNN': é›¶æ ·æœ¬å›¾ç¥ç»ç½‘ç»œï¼Œå…·æœ‰æ³›åŒ–èƒ½åŠ›ï¼Œé€‚åˆä¸åŒè§„æ¨¡åœºæ™¯
        # - 'GAT': å›¾æ³¨æ„åŠ›ç½‘ç»œï¼Œä¸“æ³¨äºå›¾ç»“æ„æ•°æ®å¤„ç†
        self.NETWORK_TYPE = 'ZeroShotGNN'    # åˆ‡æ¢åˆ°ZeroShotGNNè¿›è¡Œç¨³å®šæ€§è°ƒè¯•

        # ----- æ”¹è¿› ZeroShotGNNå¥–åŠ±å‡½æ•° -----
        self.USE_IMPROVED_REWARD = True  # å¯ç”¨æ”¹è¿›ç‰ˆå¥–åŠ±å‡½æ•°
        
        # ----- è·¯å¾„è§„åˆ’å‚æ•° -----
        # RRTç®—æ³•æ ¸å¿ƒå‚æ•°ï¼š
        self.RRT_ITERATIONS = 1000          # RRTæœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå½±å“è·¯å¾„è´¨é‡å’Œè®¡ç®—æ—¶é—´
        self.RRT_STEP_SIZE = 50.0           # RRTå•æ­¥æ‰©å±•è·ç¦»ï¼Œå½±å“è·¯å¾„å¹³æ»‘åº¦
        self.RRT_GOAL_BIAS = 0.1            # ç›®æ ‡åå‘æ¦‚ç‡(0-1)ï¼Œè¶Šå¤§è¶Šå¿«æ”¶æ•›ä½†å¯èƒ½é™·å…¥å±€éƒ¨æœ€ä¼˜
        self.RRT_ADAPTIVE_STEP = True       # è‡ªé€‚åº”æ­¥é•¿ï¼šTrue=æ ¹æ®ç¯å¢ƒè°ƒæ•´ï¼ŒFalse=å›ºå®šæ­¥é•¿
        self.RRT_OBSTACLE_AWARE = True      # éšœç¢ç‰©æ„ŸçŸ¥é‡‡æ ·ï¼šTrue=é¿å¼€éšœç¢ç‰©ï¼ŒFalse=éšæœºé‡‡æ ·
        self.RRT_MAX_ATTEMPTS = 3           # è·¯å¾„è§„åˆ’å¤±è´¥æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°
        
        # ===== PHæ›²çº¿å¹³æ»‘å‚æ•° =====
        self.MAX_REFINEMENT_ATTEMPTS = 5    # æœ€å¤§ç»†åŒ–å°è¯•æ¬¡æ•°
        self.BEZIER_SAMPLES = 50            # è´å¡å°”æ›²çº¿é‡‡æ ·ç‚¹æ•°
        self.OBSTACLE_TOLERANCE = 50.0      # éšœç¢ç‰©çš„å®‰å…¨å®¹å¿è·ç¦»

        # ----- å›¾æ„å»ºå‚æ•° -----
        # å›¾ç»“æ„ç¦»æ•£åŒ–å‚æ•°ï¼š
        self.GRAPH_N_PHI = 6                # æ¯ä¸ªç›®æ ‡èŠ‚ç‚¹çš„ç¦»æ•£åŒ–æ¥è¿‘è§’åº¦æ•°é‡ï¼Œå½±å“åŠ¨ä½œç©ºé—´å¤§å°

        # ----- ç¯å¢ƒç»´åº¦å‚æ•° -----
        # ç¯å¢ƒè§„æ¨¡é™åˆ¶ï¼ˆç”¨äºå¼ é‡ç»´åº¦ç»Ÿä¸€ï¼‰ï¼š
        self.MAX_UAVS = 10                  # æ”¯æŒçš„æœ€å¤§UAVæ•°é‡ï¼Œè¶…å‡ºä¼šæˆªæ–­
        self.MAX_TARGETS = 15               # æ”¯æŒçš„æœ€å¤§ç›®æ ‡æ•°é‡ï¼Œè¶…å‡ºä¼šæˆªæ–­
        self.MAP_SIZE = 1000.0              # åœ°å›¾è¾¹é•¿(ç±³)ï¼Œç”¨äºåæ ‡å½’ä¸€åŒ–
        self.MAX_INTERACTION_RANGE = 2000.0 # UAVæœ€å¤§äº¤äº’è·ç¦»(ç±³)ï¼Œè¶…å‡ºè§†ä¸ºæ— æ•ˆ

        # ----- æ¨¡æ‹Ÿä¸è¯„ä¼°å‚æ•° -----
        # å¯è§†åŒ–æ§åˆ¶ï¼š
        self.SHOW_VISUALIZATION = False     # æ˜¯å¦æ˜¾ç¤ºmatplotlibå¯è§†åŒ–å›¾è¡¨
        
        # è´Ÿè½½å‡è¡¡å‚æ•°ï¼š
        self.LOAD_BALANCE_PENALTY = 0.1     # è´Ÿè½½ä¸å‡è¡¡æƒ©ç½šç³»æ•°(0-1)ï¼Œè¶Šå¤§è¶Šé‡è§†å‡è¡¡

        # ----- å¥–åŠ±å‡½æ•°å‚æ•° -----
        self.TARGET_COMPLETION_REWARD = 1500    # ç›®æ ‡å®Œæˆå¥–åŠ±
        self.MARGINAL_UTILITY_FACTOR = 1000    # è¾¹é™…æ•ˆç”¨å› å­
        self.EFFICIENCY_REWARD_FACTOR = 500     # æ•ˆç‡å¥–åŠ±å› å­
        self.DISTANCE_PENALTY_FACTOR = 0.1     # è·ç¦»æƒ©ç½šå› å­
        self.TIME_PENALTY_FACTOR = 10          # æ—¶é—´æƒ©ç½šå› å­
        self.COMPLETION_REWARD = 1000          # å®Œæˆå¥–åŠ±
        self.INVALID_ACTION_PENALTY = -100     # æ— æ•ˆåŠ¨ä½œæƒ©ç½š
        self.ZERO_CONTRIBUTION_PENALTY = -50   # é›¶è´¡çŒ®æƒ©ç½š
        self.DEADLOCK_PENALTY = -200           # æ­»é”æƒ©ç½š
        self.COLLABORATION_BONUS = 200         # åä½œå¥–åŠ±

        # ----- PBRS (Potential-Based Reward Shaping) å‚æ•° -----
        # PBRSåŠŸèƒ½å¼€å…³ (æš‚æ—¶ç¦ç”¨ï¼Œå›åˆ°ç¨³å®šåŸºçº¿)
        self.ENABLE_PBRS = False                        # æš‚æ—¶ç¦ç”¨PBRSï¼Œè§£å†³ä¸ç¨³å®šé—®é¢˜
        self.PBRS_TYPE = 'simple'                       # PBRSç±»å‹: 'simple'(å®Œæˆç›®æ ‡æ•°) æˆ– 'progress'(èµ„æºè¿›åº¦)
        self.ENABLE_REWARD_LOGGING = True               # æ˜¯å¦ä¿å­˜æœ€æ–°çš„å¥–åŠ±ç»„æˆç”¨äºè°ƒè¯•å’Œç›‘æ§
        
        # åŠ¿å‡½æ•°æƒé‡å‚æ•°
        self.PBRS_COMPLETION_WEIGHT = 10.0              # å®Œæˆåº¦åŠ¿èƒ½æƒé‡
        self.PBRS_DISTANCE_WEIGHT = 0.01                # è·ç¦»åŠ¿èƒ½æƒé‡
        self.PBRS_COLLABORATION_WEIGHT = 5.0            # åä½œåŠ¿èƒ½æƒé‡
        
        # å¥–åŠ±è£å‰ªå‚æ•° (æä¿å®ˆç‰ˆæœ¬)
        self.PBRS_REWARD_CLIP_MIN = -5.0                # å¡‘å½¢å¥–åŠ±æœ€å°å€¼ (æä¿å®ˆ)
        self.PBRS_REWARD_CLIP_MAX = 5.0                 # å¡‘å½¢å¥–åŠ±æœ€å¤§å€¼ (æä¿å®ˆ)
        self.PBRS_POTENTIAL_SCALE = 0.01                # åŠ¿å‡½æ•°ç¼©æ”¾å› å­ (æå°å½±å“)
        self.PBRS_WARMUP_EPISODES = 100                 # PBRSé¢„çƒ­æœŸ (å‰100è½®ä¸ä½¿ç”¨)
        
        # è°ƒè¯•å‚æ•°
        self.PBRS_DEBUG_MODE = False                    # PBRSè°ƒè¯•æ¨¡å¼
        self.PBRS_LOG_POTENTIAL_VALUES = False          # æ˜¯å¦è®°å½•åŠ¿å‡½æ•°å€¼
        self.PBRS_LOG_REWARD_BREAKDOWN = False          # æ˜¯å¦è®°å½•å¥–åŠ±ç»„æˆè¯¦æƒ…
        
        # æ•°å€¼ç¨³å®šæ€§å‚æ•°
        self.PBRS_POTENTIAL_CLIP_MIN = -1000.0          # åŠ¿å‡½æ•°å€¼æœ€å°å€¼
        self.PBRS_POTENTIAL_CLIP_MAX = 1000.0           # åŠ¿å‡½æ•°å€¼æœ€å¤§å€¼
        self.PBRS_ENABLE_GRADIENT_CLIPPING = True       # æ˜¯å¦å¯ç”¨æ¢¯åº¦è£å‰ª
        self.PBRS_MAX_POTENTIAL_CHANGE = 100.0          # å•æ­¥æœ€å¤§åŠ¿å‡½æ•°å˜åŒ–é‡
        
        # ç¼“å­˜å’Œæ€§èƒ½å‚æ•°
        self.PBRS_ENABLE_DISTANCE_CACHE = True          # æ˜¯å¦å¯ç”¨è·ç¦»ç¼“å­˜
        self.PBRS_CACHE_UPDATE_THRESHOLD = 0.1          # ç¼“å­˜æ›´æ–°é˜ˆå€¼
        
        # ----- ç´§æ€¥ç¨³å®šæ€§ä¿®å¤å‚æ•° -----
        # å¥–åŠ±å½’ä¸€åŒ–ä¼˜åŒ–
        self.REWARD_NORMALIZATION = True           # å¯ç”¨å¥–åŠ±å½’ä¸€åŒ–
        self.REWARD_SCALE = 0.3                    # ä»0.1æå‡åˆ°0.3 (3å€)
        
        # æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
        self.ENABLE_NUMERICAL_STABILITY_CHECKS = True  # å¯ç”¨æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
        
        # ----- è®­ç»ƒé…ç½®å¯¹è±¡ -----
        self.training_config = TrainingConfig()
        
        # æ ¹æ®ç½‘ç»œç±»å‹è®¾ç½®ä¼˜åŒ–çš„å‚æ•°é…ç½®
        self._setup_network_specific_params()
        
        # è®¾ç½®ç»Ÿä¸€çš„è®­ç»ƒå‚æ•°è®¿é—®æ¥å£
        self._setup_unified_training_params()
        
        # éªŒè¯PBRSé…ç½®
        self._validate_pbrs_on_init()
    
    def _setup_network_specific_params(self):
        """æ ¹æ®ç½‘ç»œç±»å‹è®¾ç½®ä¼˜åŒ–çš„å‚æ•°é…ç½®"""
        
        if self.NETWORK_TYPE == 'DeepFCN':
            # DeepFCNç¨³å®šè®­ç»ƒå‚æ•° (ç»è¿‡æµ‹è¯•éªŒè¯çš„æœ€ä½³é…ç½®)
            print(f"ğŸ¯ åº”ç”¨DeepFCNç¨³å®šè®­ç»ƒå‚æ•°é…ç½®")
            self.training_config.learning_rate = 1e-05              # æä½å­¦ä¹ ç‡ï¼Œé¿å…è®­ç»ƒéœ‡è¡
            self.training_config.gradient_clip_norm = 0.5           # ä¸¥æ ¼æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
            self.training_config.weight_decay = 2e-05               # é«˜æ­£åˆ™åŒ–ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆå’Œæ•°å€¼ä¸ç¨³å®š
            self.training_config.target_update_frequency = 1500     # ç¨³å®šçš„ç›®æ ‡ç½‘ç»œæ›´æ–°
            self.training_config.batch_size = 64                   # ä¸­ç­‰æ‰¹æ¬¡å¤§å°ï¼Œå¹³è¡¡ç¨³å®šæ€§å’Œæ•ˆç‡
            self.training_config.epsilon_decay = 0.995             # å¹³æ»‘æ¢ç´¢è¡°å‡
            self.training_config.epsilon_min = 0.05                # ä¿æŒæœ€å°æ¢ç´¢
            
        elif self.NETWORK_TYPE == 'ZeroShotGNN':
            # ZeroShotGNNä¼˜åŒ–é…ç½® (åŸºäºé—®é¢˜åˆ†æ)
            print(f"ğŸš€ åº”ç”¨ZeroShotGNNä¼˜åŒ–é…ç½®")
            self.training_config.learning_rate = 1e-05              # æä½å­¦ä¹ ç‡ï¼Œå€Ÿé‰´DeepFCNæˆåŠŸç»éªŒ
            self.training_config.gradient_clip_norm = 0.5           # ä¸¥æ ¼æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢å›¾ç½‘ç»œæ¢¯åº¦ä¸ç¨³å®š
            self.training_config.weight_decay = 2e-05               # é«˜æ­£åˆ™åŒ–ï¼Œå¢å¼ºç¨³å®šæ€§
            self.training_config.target_update_frequency = 2000     # æ›´ç¨³å®šçš„ç›®æ ‡ç½‘ç»œæ›´æ–°
            self.training_config.batch_size = 16                   # å°æ‰¹æ¬¡ï¼Œå‡å°‘è®¡ç®—å¼€é”€
            self.training_config.epsilon_decay = 0.998             # æ›´æ…¢çš„æ¢ç´¢è¡°å‡ï¼Œé€‚åˆå›¾ç½‘ç»œ
            self.training_config.epsilon_min = 0.1                 # ä¿æŒè¾ƒé«˜æœ€å°æ¢ç´¢
        elif self.NETWORK_TYPE == 'SimpleNetwork':
            # SimpleNetworkåŸºç¡€é…ç½®
            print(f"âš¡ åº”ç”¨SimpleNetworkåŸºç¡€å‚æ•°é…ç½®")
            self.training_config.learning_rate = 1e-04              # æ ‡å‡†å­¦ä¹ ç‡
            self.training_config.gradient_clip_norm = 1.0           # æ ‡å‡†æ¢¯åº¦è£å‰ª
            self.training_config.weight_decay = 1e-06               # ä½æ­£åˆ™åŒ–
            self.training_config.target_update_frequency = 500      # é¢‘ç¹æ›´æ–°
            self.training_config.batch_size = 128                  # å¤§æ‰¹æ¬¡
            self.training_config.epsilon_decay = 0.995             # æ ‡å‡†è¡°å‡
            self.training_config.epsilon_min = 0.01                # ä½æœ€å°æ¢ç´¢
            
        elif self.NETWORK_TYPE == 'DeepFCNResidual':
            # DeepFCNResidualé…ç½® (åŸºäºDeepFCNä¼˜åŒ–)
            print(f"ğŸš€ åº”ç”¨DeepFCNResidualå‚æ•°é…ç½®")
            self.training_config.learning_rate = 2e-05              # ç•¥é«˜äºDeepFCN
            self.training_config.gradient_clip_norm = 0.8           # é€‚ä¸­æ¢¯åº¦è£å‰ª
            self.training_config.weight_decay = 1e-05               # ä¸­ç­‰æ­£åˆ™åŒ–
            self.training_config.target_update_frequency = 1200     # é€‚ä¸­æ›´æ–°é¢‘ç‡
            self.training_config.batch_size = 64                   # ä¸DeepFCNç›¸åŒ
            self.training_config.epsilon_decay = 0.996             # ç•¥å¿«è¡°å‡
            self.training_config.epsilon_min = 0.05                # æ ‡å‡†æœ€å°æ¢ç´¢
            
        else:
            # é»˜è®¤é…ç½®
            print(f"âš ï¸ ä½¿ç”¨é»˜è®¤å‚æ•°é…ç½® (ç½‘ç»œç±»å‹: {self.NETWORK_TYPE})")
            self.training_config.learning_rate = 1e-04
            self.training_config.gradient_clip_norm = 1.0
            self.training_config.weight_decay = 1e-05
            self.training_config.target_update_frequency = 1000
            self.training_config.batch_size = 64
            self.training_config.epsilon_decay = 0.995
            self.training_config.epsilon_min = 0.05
        
        print(f"âœ… ç½‘ç»œç‰¹å®šå‚æ•°é…ç½®å®Œæˆ")
        print(f"   å­¦ä¹ ç‡: {self.training_config.learning_rate}")
        print(f"   æ¢¯åº¦è£å‰ª: {self.training_config.gradient_clip_norm}")
        print(f"   æƒé‡è¡°å‡: {self.training_config.weight_decay}")
        print(f"   æ‰¹æ¬¡å¤§å°: {self.training_config.batch_size}")
    
    def _setup_unified_training_params(self):
        """
        è®¾ç½®ç»Ÿä¸€çš„è®­ç»ƒå‚æ•°è®¿é—®æ¥å£
        æ‰€æœ‰è®­ç»ƒç›¸å…³å‚æ•°éƒ½é€šè¿‡training_configç»Ÿä¸€ç®¡ç†ï¼Œé¿å…é‡å¤å®šä¹‰
        """
        # ä¸ºäº†å‘åå…¼å®¹ï¼Œæä¾›å±æ€§è®¿é—®æ¥å£
        pass
    
    def _validate_pbrs_on_init(self):
        """åœ¨åˆå§‹åŒ–æ—¶éªŒè¯PBRSé…ç½®"""
        if not self.validate_pbrs_config():
            print("âš ï¸  è­¦å‘Š: PBRSé…ç½®åˆå§‹åŒ–éªŒè¯å¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼")
            self.reset_pbrs_to_defaults()
    
    # ===== ç»Ÿä¸€çš„è®­ç»ƒå‚æ•°è®¿é—®å±æ€§ =====
    @property
    def EPISODES(self):
        return self.training_config.episodes
    
    @EPISODES.setter
    def EPISODES(self, value):
        self.training_config.episodes = value
    
    @property
    def LEARNING_RATE(self):
        return self.training_config.learning_rate
    
    @LEARNING_RATE.setter
    def LEARNING_RATE(self, value):
        self.training_config.learning_rate = 1e-05
    
    @property
    def GAMMA(self):
        return self.training_config.gamma
    
    @GAMMA.setter
    def GAMMA(self, value):
        self.training_config.gamma = value
    
    @property
    def BATCH_SIZE(self):
        return self.training_config.batch_size
    
    @BATCH_SIZE.setter
    def BATCH_SIZE(self, value):
        self.training_config.batch_size = value
    
    @property
    def MEMORY_SIZE(self):
        return self.training_config.memory_size
    
    @MEMORY_SIZE.setter
    def MEMORY_SIZE(self, value):
        self.training_config.memory_size = value
    
    @property
    def MEMORY_CAPACITY(self):
        return self.training_config.memory_size
    
    @MEMORY_CAPACITY.setter
    def MEMORY_CAPACITY(self, value):
        self.training_config.memory_size = value
    
    @property
    def EPSILON_START(self):
        return self.training_config.epsilon_start
    
    @EPSILON_START.setter
    def EPSILON_START(self, value):
        self.training_config.epsilon_start = value
    
    @property
    def EPSILON_END(self):
        return self.training_config.epsilon_end
    
    @EPSILON_END.setter
    def EPSILON_END(self, value):
        self.training_config.epsilon_end = value
    
    @property
    def EPSILON_DECAY(self):
        return self.training_config.epsilon_decay
    
    @EPSILON_DECAY.setter
    def EPSILON_DECAY(self, value):
        self.training_config.epsilon_decay = value
    
    @property
    def EPSILON_MIN(self):
        return self.training_config.epsilon_min
    
    @EPSILON_MIN.setter
    def EPSILON_MIN(self, value):
        self.training_config.epsilon_min = value
    
    @property
    def TARGET_UPDATE_FREQ(self):
        return self.training_config.target_update_freq
    
    @TARGET_UPDATE_FREQ.setter
    def TARGET_UPDATE_FREQ(self, value):
        self.training_config.target_update_freq = value
    
    @property
    def PATIENCE(self):
        return self.training_config.patience
    
    @PATIENCE.setter
    def PATIENCE(self, value):
        self.training_config.patience = value
    
    @property
    def LOG_INTERVAL(self):
        return self.training_config.log_interval
    
    @LOG_INTERVAL.setter
    def LOG_INTERVAL(self, value):
        self.training_config.log_interval = value
    
    # ===== ä¾¿æ·çš„å‚æ•°ä¿®æ”¹æ–¹æ³• =====
    def update_training_params(self, **kwargs):
        """
        ä¾¿æ·çš„è®­ç»ƒå‚æ•°æ‰¹é‡æ›´æ–°æ–¹æ³•
        
        ä½¿ç”¨ç¤ºä¾‹:
        config.update_training_params(
            episodes=1000,
            learning_rate=0.001,
            batch_size=128
        )
        """
        for key, value in kwargs.items():
            if hasattr(self.training_config, key):
                setattr(self.training_config, key, value)
                print(f"âœ“ æ›´æ–°è®­ç»ƒå‚æ•°: {key} = {value}")
            else:
                print(f"âœ— è­¦å‘Š: æœªçŸ¥çš„è®­ç»ƒå‚æ•° '{key}'")
    
    def get_training_summary(self):
        """è·å–å½“å‰è®­ç»ƒå‚æ•°æ‘˜è¦"""
        summary = {
            "åŸºç¡€å‚æ•°": {
                "episodes": self.training_config.episodes,
                "learning_rate": self.training_config.learning_rate,
                "gamma": self.training_config.gamma,
                "batch_size": self.training_config.batch_size,
                "memory_size": self.training_config.memory_size,
            },
            "æ¢ç´¢ç­–ç•¥": {
                "epsilon_start": self.training_config.epsilon_start,
                "epsilon_end": self.training_config.epsilon_end,
                "epsilon_decay": self.training_config.epsilon_decay,
                "epsilon_min": self.training_config.epsilon_min,
            },
            "ç½‘ç»œæ›´æ–°": {
                "target_update_freq": self.training_config.target_update_freq,
                "patience": self.training_config.patience,
                "log_interval": self.training_config.log_interval,
            },
            "ä¼˜å…ˆç»éªŒå›æ”¾": {
                "use_prioritized_replay": self.training_config.use_prioritized_replay,
                "per_alpha": self.training_config.per_alpha,
                "per_beta_start": self.training_config.per_beta_start,
                "per_beta_frames": self.training_config.per_beta_frames,
            }
        }
        return summary
    
    def print_training_config(self):
        """æ‰“å°å½“å‰è®­ç»ƒé…ç½®"""
        print("=" * 60)
        print("å½“å‰è®­ç»ƒé…ç½®å‚æ•°")
        print("=" * 60)
        
        summary = self.get_training_summary()
        for category, params in summary.items():
            print(f"\n{category}:")
            print("-" * 30)
            for key, value in params.items():
                print(f"  {key}: {value}")
        
        print("\n" + "=" * 60)
        
        # æ–°å¢çš„è®­ç»ƒå‚æ•°
        self.use_gradient_clipping = self.training_config.use_gradient_clipping
        self.max_grad_norm = self.training_config.max_grad_norm
    
    def update_training_config(self, new_config: TrainingConfig):
        """æ›´æ–°è®­ç»ƒé…ç½®"""
        self.training_config = new_config
        self._setup_backward_compatibility()
    
    def get_training_config(self) -> TrainingConfig:
        """è·å–å½“å‰è®­ç»ƒé…ç½®"""
        return self.training_config
    
    def load_existing_model(self, model_path: str = None) -> bool:
        """å°è¯•åŠ è½½å·²å­˜åœ¨çš„æ¨¡å‹"""
        if model_path is None:
            model_path = self.SAVED_MODEL_PATH
        
        if os.path.exists(model_path):
            print(f"å‘ç°å·²å­˜åœ¨çš„æ¨¡å‹: {model_path}")
            return True
        return False
    
    # ===== è®­ç»ƒæ¨¡å¼ä¾¿æ·æ–¹æ³• =====
    def set_training_mode(self, mode: str):
        """è®¾ç½®è®­ç»ƒæ¨¡å¼"""
        valid_modes = ['training', 'inference', 'zero_shot_train']
        if mode not in valid_modes:
            raise ValueError(f"æ— æ•ˆçš„è®­ç»ƒæ¨¡å¼: {mode}ã€‚æœ‰æ•ˆæ¨¡å¼: {valid_modes}")
        self.TRAINING_MODE = mode
    
    def is_training_mode(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºè®­ç»ƒæ¨¡å¼"""
        return self.TRAINING_MODE == 'training'
    
    def is_inference_mode(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæ¨ç†æ¨¡å¼"""
        return self.TRAINING_MODE == 'inference'
    
    # ===== PBRSé…ç½®ç®¡ç†æ–¹æ³• =====
    def validate_pbrs_config(self) -> bool:
        """
        éªŒè¯PBRSé…ç½®å‚æ•°çš„æœ‰æ•ˆæ€§
        
        Returns:
            bool: é…ç½®æ˜¯å¦æœ‰æ•ˆ
        """
        validation_errors = []
        
        # éªŒè¯æƒé‡å‚æ•°
        if self.PBRS_COMPLETION_WEIGHT < 0:
            validation_errors.append("PBRS_COMPLETION_WEIGHTå¿…é¡»ä¸ºéè´Ÿæ•°")
        
        if self.PBRS_DISTANCE_WEIGHT < 0:
            validation_errors.append("PBRS_DISTANCE_WEIGHTå¿…é¡»ä¸ºéè´Ÿæ•°")
        
        if self.PBRS_COLLABORATION_WEIGHT < 0:
            validation_errors.append("PBRS_COLLABORATION_WEIGHTå¿…é¡»ä¸ºéè´Ÿæ•°")
        
        # éªŒè¯è£å‰ªå‚æ•°
        if self.PBRS_REWARD_CLIP_MIN >= self.PBRS_REWARD_CLIP_MAX:
            validation_errors.append("PBRS_REWARD_CLIP_MINå¿…é¡»å°äºPBRS_REWARD_CLIP_MAX")
        
        if self.PBRS_POTENTIAL_CLIP_MIN >= self.PBRS_POTENTIAL_CLIP_MAX:
            validation_errors.append("PBRS_POTENTIAL_CLIP_MINå¿…é¡»å°äºPBRS_POTENTIAL_CLIP_MAX")
        
        # éªŒè¯æ•°å€¼ç¨³å®šæ€§å‚æ•°
        if self.PBRS_MAX_POTENTIAL_CHANGE <= 0:
            validation_errors.append("PBRS_MAX_POTENTIAL_CHANGEå¿…é¡»ä¸ºæ­£æ•°")
        
        if self.PBRS_CACHE_UPDATE_THRESHOLD <= 0 or self.PBRS_CACHE_UPDATE_THRESHOLD >= 1:
            validation_errors.append("PBRS_CACHE_UPDATE_THRESHOLDå¿…é¡»åœ¨(0,1)èŒƒå›´å†…")
        
        # è¾“å‡ºéªŒè¯ç»“æœ
        if validation_errors:
            print("PBRSé…ç½®éªŒè¯å¤±è´¥:")
            for error in validation_errors:
                print(f"  âœ— {error}")
            return False
        else:
            if self.PBRS_DEBUG_MODE:
                print("âœ“ PBRSé…ç½®éªŒè¯é€šè¿‡")
            return True
    
    def get_pbrs_config_summary(self) -> Dict[str, Any]:
        """è·å–PBRSé…ç½®æ‘˜è¦"""
        return {
            "åŠŸèƒ½å¼€å…³": {
                "ENABLE_PBRS": self.ENABLE_PBRS,
                "PBRS_DEBUG_MODE": self.PBRS_DEBUG_MODE,
                "PBRS_LOG_POTENTIAL_VALUES": self.PBRS_LOG_POTENTIAL_VALUES,
                "PBRS_LOG_REWARD_BREAKDOWN": self.PBRS_LOG_REWARD_BREAKDOWN,
            },
            "åŠ¿å‡½æ•°æƒé‡": {
                "PBRS_COMPLETION_WEIGHT": self.PBRS_COMPLETION_WEIGHT,
                "PBRS_DISTANCE_WEIGHT": self.PBRS_DISTANCE_WEIGHT,
                "PBRS_COLLABORATION_WEIGHT": self.PBRS_COLLABORATION_WEIGHT,
            },
            "æ•°å€¼ç¨³å®šæ€§": {
                "PBRS_REWARD_CLIP_MIN": self.PBRS_REWARD_CLIP_MIN,
                "PBRS_REWARD_CLIP_MAX": self.PBRS_REWARD_CLIP_MAX,
                "PBRS_POTENTIAL_CLIP_MIN": self.PBRS_POTENTIAL_CLIP_MIN,
                "PBRS_POTENTIAL_CLIP_MAX": self.PBRS_POTENTIAL_CLIP_MAX,
                "PBRS_MAX_POTENTIAL_CHANGE": self.PBRS_MAX_POTENTIAL_CHANGE,
            },
            "æ€§èƒ½ä¼˜åŒ–": {
                "PBRS_ENABLE_DISTANCE_CACHE": self.PBRS_ENABLE_DISTANCE_CACHE,
                "PBRS_CACHE_UPDATE_THRESHOLD": self.PBRS_CACHE_UPDATE_THRESHOLD,
                "PBRS_ENABLE_GRADIENT_CLIPPING": self.PBRS_ENABLE_GRADIENT_CLIPPING,
            }
        }
    
    def print_pbrs_config(self):
        """æ‰“å°PBRSé…ç½®å‚æ•°"""
        print("=" * 60)
        print("PBRS (Potential-Based Reward Shaping) é…ç½®å‚æ•°")
        print("=" * 60)
        
        summary = self.get_pbrs_config_summary()
        for category, params in summary.items():
            print(f"\n{category}:")
            print("-" * 30)
            for key, value in params.items():
                print(f"  {key}: {value}")
        
        print("\n" + "=" * 60)
    
    def update_pbrs_params(self, **kwargs):
        """
        ä¾¿æ·çš„PBRSå‚æ•°æ‰¹é‡æ›´æ–°æ–¹æ³•
        
        ä½¿ç”¨ç¤ºä¾‹:
        config.update_pbrs_params(
            PBRS_COMPLETION_WEIGHT=15.0,
            PBRS_DEBUG_MODE=True,
            ENABLE_PBRS=False
        )
        """
        pbrs_params = [attr for attr in dir(self) if attr.startswith('PBRS_') or attr == 'ENABLE_PBRS']
        
        for key, value in kwargs.items():
            if key in pbrs_params:
                setattr(self, key, value)
                print(f"âœ“ æ›´æ–°PBRSå‚æ•°: {key} = {value}")
            else:
                print(f"âœ— è­¦å‘Š: æœªçŸ¥çš„PBRSå‚æ•° '{key}'")
        
        # æ›´æ–°åé‡æ–°éªŒè¯é…ç½®
        if not self.validate_pbrs_config():
            print("âš ï¸  è­¦å‘Š: PBRSé…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥å‚æ•°è®¾ç½®")
    
    def reset_pbrs_to_defaults(self):
        """é‡ç½®PBRSå‚æ•°ä¸ºé»˜è®¤å€¼"""
        self.ENABLE_PBRS = True
        self.PBRS_COMPLETION_WEIGHT = 10.0
        self.PBRS_DISTANCE_WEIGHT = 0.01
        self.PBRS_COLLABORATION_WEIGHT = 5.0
        self.PBRS_REWARD_CLIP_MIN = -50.0
        self.PBRS_REWARD_CLIP_MAX = 50.0
        self.PBRS_DEBUG_MODE = False
        self.PBRS_LOG_POTENTIAL_VALUES = False
        self.PBRS_LOG_REWARD_BREAKDOWN = False
        self.PBRS_POTENTIAL_CLIP_MIN = -1000.0
        self.PBRS_POTENTIAL_CLIP_MAX = 1000.0
        self.PBRS_ENABLE_GRADIENT_CLIPPING = True
        self.PBRS_MAX_POTENTIAL_CHANGE = 100.0
        self.PBRS_ENABLE_DISTANCE_CACHE = True
        self.PBRS_CACHE_UPDATE_THRESHOLD = 0.1
        
        print("âœ“ PBRSå‚æ•°å·²é‡ç½®ä¸ºé»˜è®¤å€¼")
        self.validate_pbrs_config()
    
    def is_pbrs_enabled(self) -> bool:
        """æ£€æŸ¥PBRSåŠŸèƒ½æ˜¯å¦å¯ç”¨"""
        return self.ENABLE_PBRS and self.validate_pbrs_config()
    
    def save_pbrs_config(self, filepath: str = "pbrs_config.pkl"):
        """
        ä¿å­˜PBRSé…ç½®åˆ°æ–‡ä»¶
        
        Args:
            filepath: ä¿å­˜è·¯å¾„ï¼Œé»˜è®¤ä¸ºpbrs_config.pkl
        """
        pbrs_config = self.get_pbrs_config_summary()
        try:
            with open(filepath, 'wb') as f:
                pickle.dump(pbrs_config, f)
            print(f"âœ“ PBRSé…ç½®å·²ä¿å­˜åˆ°: {filepath}")
        except Exception as e:
            print(f"âœ— ä¿å­˜PBRSé…ç½®å¤±è´¥: {e}")
    
    def load_pbrs_config(self, filepath: str = "pbrs_config.pkl"):
        """
        ä»æ–‡ä»¶åŠ è½½PBRSé…ç½®
        
        Args:
            filepath: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        try:
            with open(filepath, 'rb') as f:
                pbrs_config = pickle.load(f)
            
            # å±•å¹³é…ç½®å­—å…¸å¹¶æ›´æ–°å‚æ•°
            flat_config = {}
            for category, params in pbrs_config.items():
                flat_config.update(params)
            
            self.update_pbrs_params(**flat_config)
            print(f"âœ“ PBRSé…ç½®å·²ä» {filepath} åŠ è½½")
            
        except FileNotFoundError:
            print(f"âœ— é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
        except Exception as e:
            print(f"âœ— åŠ è½½PBRSé…ç½®å¤±è´¥: {e}")
    
    # å‘åå…¼å®¹çš„æ–¹æ³•
    @property
    def RUN_TRAINING(self) -> bool:
        """å‘åå…¼å®¹çš„RUN_TRAININGå±æ€§"""
        return self.is_training_mode()
    
    @RUN_TRAINING.setter
    def RUN_TRAINING(self, value: bool):
        """å‘åå…¼å®¹çš„RUN_TRAININGè®¾ç½®å™¨"""
        self.TRAINING_MODE = 'training' if value else 'inference'